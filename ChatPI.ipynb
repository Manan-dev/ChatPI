{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/Manan-dev/ChatPI.git@main\n",
    "!git clone https://github.com/Manan-dev/ChatPI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatpi.utils import read_context, read_quiz\n",
    "from chatpi.question_answering import run_qa\n",
    "from chatpi.translation import run_tr\n",
    "from chatpi.summarization import run_sum\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatBot Implementation\n",
    "- Using the functions from our repository, we will implement a chatbot that will be able to answer questions about the 5 different text excerpts, translate these questions to French and back to English, and give summarizations about the text excerpts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "qa_models = [\n",
    "    # DistilBERT\n",
    "    \"distilbert-base-cased-distilled-squad\",\n",
    "    \"distilbert-base-uncased-distilled-squad\",\n",
    "    # RoBERTa\n",
    "    \"deepset/roberta-base-squad2\",\n",
    "    \"deepset/roberta-large-squad2\",\n",
    "    # Deberta\n",
    "    \"deepset/deberta-v3-base-squad2\",\n",
    "    \"deepset/deberta-v3-large-squad2\",\n",
    "    # Electra\n",
    "    \"deepset/electra-base-squad2\",\n",
    "]\n",
    "'''\n",
    "'''\n",
    "tr_models = [\n",
    "    \"Helsinki-NLP/opus-mt-en-fr\",\n",
    "    \"Helsinki-NLP/opus-mt-fr-en\",\n",
    "    \"facebook/m2m100_418M\",\n",
    "]\n",
    "'''\n",
    "'''\n",
    "sum_models = [\n",
    "    \"sshleifer/distilbart-cnn-12-6\",\n",
    "    \"slauw87/bart_summarisation\",\n",
    "    \"pszemraj/pegasus-x-large-book-summary\",\n",
    "]\n",
    "'''\n",
    "\n",
    "# These were used for demo because they were fast. Other models, some more performant, are commented out above.\n",
    "default_qa_model = 'deepset/deberta-v3-base-squad2'\n",
    "default_tr_model = 'facebook/m2m100_418M'\n",
    "default_sum_model = 'sshleifer/distilbart-cnn-12-6'\n",
    "\n",
    "\n",
    "def get_context_and_question(ctx_name):\n",
    "    question_list = []\n",
    "\n",
    "    for ctx_idx, (ctx_fname, ctx_text) in enumerate(read_context(ctx_name, basepath=\"/content/ChatPI/sections\")):\n",
    "        ctx_fname = os.path.basename(ctx_fname)\n",
    "\n",
    "        for q_idx, (q_text, q_answer_true) in enumerate(read_quiz(ctx_name, basepath=\"/content/ChatPI/sections\")):\n",
    "            question_list.append(q_text)\n",
    "\n",
    "        return ctx_fname, ctx_text, question_list\n",
    "\n",
    "\n",
    "def run_pipelines_for_context(ctx_name):\n",
    "    print(f'Loading {ctx_name} context...\\n')\n",
    "    _, text, questions = get_context_and_question(ctx_name)\n",
    "    questions.append(\"Can you summarize the context?\")\n",
    "\n",
    "    print(f'{ctx_name} CONTEXT')\n",
    "    print(\"===\" * 80)\n",
    "    print(text)\n",
    "    print(\"===\" * 80)\n",
    "    print(f'Here is a list of questions you can ask about the {ctx_name}')\n",
    "\n",
    "    for idx, question in enumerate(questions):\n",
    "        print(f'  [{idx}] {question}')\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nPlease enter a question number or type 'return' to go back to context selection\\n\")\n",
    "        user_input = input(\"> \")\n",
    "        \n",
    "        if user_input == 'return':\n",
    "            print(\"Returning to context selection...\\n\")\n",
    "            break\n",
    "\n",
    "        elif int(user_input) == len(questions)-1:\n",
    "            print(\"Calling Summarization Pipeline...\")\n",
    "            summarized_text = run_sum(text, model=default_sum_model)\n",
    "            print(\"> \", questions[int(user_input)])\n",
    "            print(\"> Answer from Summarization Pipeline: \", summarized_text)\n",
    "\n",
    "        elif int(user_input) < len(questions):\n",
    "            print(\"Calling QA and Translation Pipelines...\")\n",
    "            qa_answer = run_qa(questions[int(user_input)], text, model=default_qa_model)\n",
    "            french_translation_answer = run_tr(qa_answer, model=default_tr_model, pipeline_name='translation_en_to_fr')\n",
    "            english_translation_answer = run_tr(french_translation_answer, model=default_tr_model, pipeline_name='translation_fr_to_en')\n",
    "            print(\"> \", questions[int(user_input)])\n",
    "            print(\"> Answer from QA Pipeline: \", qa_answer)\n",
    "            print(\"> Answer from Translation Pipeline (French): \", french_translation_answer)\n",
    "            print(\"> Answer from Translation Pipeline (English): \", english_translation_answer)\n",
    "        \n",
    "        else:\n",
    "            print(\"Not a valid command or question..\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "  ____ _           _   ____ ___ \n",
      " / ___| |__   __ _| |_|  _ \\_ _|\n",
      "| |   | '_ \\ / _` | __| |_) | | \n",
      "| |___| | | | (_| | |_|  __/| | \n",
      " \\____|_| |_|\\__,_|\\__|_|  |___|\n",
      " \n",
      " by. Andrei Cozma, Manan Patel, Tulsi Tailor, Zac Perry\n",
      "==================================================================\n",
      "    \n",
      "Welcome! Please select a context!\n",
      "[1] Protagonist\n",
      "[2] Antagonist\n",
      "[3] Crime\n",
      "[4] Evidence\n",
      "[5] Resolution\n",
      "\n",
      "Type 'help' for more commands!\n",
      "Loading protagonist context...\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mmatch\u001b[39;00m user_input\u001b[39m.\u001b[39mlower():\n\u001b[1;32m     29\u001b[0m   \u001b[39mcase\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mprotagonist\u001b[39m\u001b[39m'\u001b[39m \u001b[39m|\u001b[39m \u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     run_pipelines_for_context(\u001b[39m\"\u001b[39;49m\u001b[39mprotagonist\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     32\u001b[0m   \u001b[39mcase\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mantagonist\u001b[39m\u001b[39m'\u001b[39m \u001b[39m|\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     33\u001b[0m     run_pipelines_for_context(\u001b[39m\"\u001b[39m\u001b[39mantagonist\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 51\u001b[0m, in \u001b[0;36mrun_pipelines_for_context\u001b[0;34m(ctx_name)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_pipelines_for_context\u001b[39m(ctx_name):\n\u001b[1;32m     50\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoading \u001b[39m\u001b[39m{\u001b[39;00mctx_name\u001b[39m}\u001b[39;00m\u001b[39m context...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m     _, text, questions \u001b[39m=\u001b[39m get_context_and_question(ctx_name)\n\u001b[1;32m     52\u001b[0m     questions\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mCan you summarize the context?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mctx_name\u001b[39m}\u001b[39;00m\u001b[39m CONTEXT\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "logo = \"\"\"\n",
    "==================================================================\n",
    "  ____ _           _   ____ ___ \n",
    " / ___| |__   __ _| |_|  _ \\_ _|\n",
    "| |   | '_ \\ / _` | __| |_) | | \n",
    "| |___| | | | (_| | |_|  __/| | \n",
    " \\____|_| |_|\\__,_|\\__|_|  |___|\n",
    " \n",
    " by. Andrei Cozma, Manan Patel, Tulsi Tailor, Zac Perry\n",
    "==================================================================\n",
    "    \"\"\"\n",
    "print(logo)\n",
    "print(\"Welcome! Please select a context!\")\n",
    "print(\"[1] Protagonist\\n[2] Antagonist\\n[3] Crime\\n[4] Evidence\\n[5] Resolution\\n\")\n",
    "print(\"Type 'help' for more commands!\")\n",
    "\n",
    "context_dictionary = {\n",
    "    1: \"protagonist\",\n",
    "    2: \"antagonist\",\n",
    "    3: \"crime\",\n",
    "    4: \"evidence\",\n",
    "    5: \"resolution\"\n",
    "}\n",
    "\n",
    "while True:  \n",
    "    user_input = input(\"> \")\n",
    "\n",
    "    match user_input.lower():\n",
    "      case 'protagonist' | '1':\n",
    "        run_pipelines_for_context(\"protagonist\")\n",
    "\n",
    "      case 'antagonist' | '2':\n",
    "        run_pipelines_for_context(\"antagonist\")\n",
    "\n",
    "      case 'crime' | '3':\n",
    "        run_pipelines_for_context(\"crime\")\n",
    "\n",
    "      case 'evidence' | '4':\n",
    "        run_pipelines_for_context(\"evidence\")\n",
    "\n",
    "      case 'resolution' | '5':\n",
    "        run_pipelines_for_context(\"resolution\")\n",
    "\n",
    "      case 'help':\n",
    "        print(\"Select a context: \\n[1] Protagonist\\n[2] Antagonist\\n[3] Crime\\n[4] Evidence\\n[5] Resolution\\n\\nOr type\\nHelp -- list commands\\nQuit -- exit the program\\n\")\n",
    "\n",
    "      case 'quit':\n",
    "        print(\"Exiting program...\\n\")\n",
    "        break\n",
    "\n",
    "      case _:\n",
    "        print(\"Please enter a command\\n\")\n",
    "\n",
    "print(\"Goodbye!\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e22577b96ae4292ce4f56ac62ee5d572607fd90aee9aa8e67f8a1f5a6d69949d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
