{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# for chunk in chunks[:3]:\n",
    "chunk_vec = tokenizer(chunks, padding=True, return_tensors=\"pt\")['input_ids']\n",
    "print(chunk_vec.shape)\n",
    "\n",
    "# chunks_vecs.append(chunk_vec)\n",
    "print(type(chunk_vec))\n",
    "for ch in chunk_vec:\n",
    "  print(len(ch))\n",
    "print('-----------------------')\n",
    "\n",
    "question = \"\"\"\n",
    "crime scene\n",
    "\"\"\"\n",
    "\n",
    "question = question.strip()\n",
    "question_vec = tokenizer(question, padding=True, return_tensors=\"pt\")['input_ids']\n",
    "\n",
    "vec_len = len(chunk_vec[0])\n",
    "# print(question_vec.shape)\n",
    "# print(vec_len)\n",
    "# pad 0 to question_vec\n",
    "question_vec = torch.cat((question_vec, torch.zeros((1, vec_len - len(question_vec[0])), dtype=chunk_vec.dtype)), dim=1)\n",
    "\n",
    "# print(question_vec.shape)\n",
    "chunk_vec = chunk_vec.float()\n",
    "question_vec = question_vec.float()\n",
    "cs = torch.nn.functional.cosine_similarity(chunk_vec, question_vec, dim=1)\n",
    "print(cs.argmax(dim=0))\n",
    "# print top 3 most cs chunks\n",
    "topk = cs.topk(3)\n",
    "# print chunks at topk indices\n",
    "for i in topk.indices:\n",
    "  print(i)\n",
    "  print(display(Markdown(chunks[i])))\n",
    "  print(cs[i])\n",
    "  print('-'*100)\n",
    "\n",
    "# print first occurence of question in text based on cs\n",
    "print(cs.argmax(dim=0))\n",
    "print(cs)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
