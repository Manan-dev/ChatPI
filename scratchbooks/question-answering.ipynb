{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Question Answering\n",
    "\n",
    "For the first part, use the Hugging Face question-answering pipeline and feed it with the five 300-word long sections from the book of your choice that you analyzed in Project 1.\n",
    "\n",
    "These sections should be selected so they are: introducing the protagonist(s), the antagonist, the crime and crime scene, any significant evidence, and the resolution of the crime/a narrative that presents the case against the perpetrator.\n",
    "\n",
    "For a prompt, Implement a simple prompt interface that takes in your question, runs it against the model, and returns the answer. You don't need to do anything special about this, just a simple console I/O interface without any complicated error handling. It is up to you how you want to upload the context to the model (pre-loaded into your program, on-demand, etc.).\n",
    "\n",
    "The questions you should ask are about the identity and characteristics of the protagonist, antagonist/perpetrator, the nature and the setting of the crime or crime scene, the evidence, and the case against the perpetrator.\n",
    "\n",
    "Document the questions, ask the questions, and document the specificity and accuracy of the results.\n",
    "\n",
    "Part 1.2 - use two different HF QA models: use the default question-answering pipeline, then use other models of choice and discuss the differences in the result.\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "https://huggingface.co/docs/transformers/v4.35.0/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Interface\n",
    "\n",
    "For a prompt, Implement a simple prompt interface that takes in your question, runs it against the model, and returns the answer.\n",
    "\n",
    "You don't need to do anything special about this, just a simple console I/O interface without any complicated error handling.\n",
    "\n",
    "It is up to you how you want to upload the context to the model (pre-loaded into your program, on-demand, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    question: str,\n",
    "    context: str,\n",
    "    model: Optional[str] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"model: {model}\")\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    print(\"~\" * 80)\n",
    "\n",
    "    # Construct Pipeline\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    pipe = pipeline(\n",
    "        \"question-answering\",\n",
    "        model=model,\n",
    "        # model=\"deepset/roberta-base-squad2\",\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Run Pipeline\n",
    "\n",
    "    question = question.strip()\n",
    "    context = context.strip()\n",
    "\n",
    "    print(f\"C: {context}\")\n",
    "    print(f\"Q: {question}\")\n",
    "    # display(Markdown(f\"**Q:** {question}\"))\n",
    "    # display(Markdown(f\"**C:** {context}\"))\n",
    "\n",
    "    res = pipe(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        **kwargs,\n",
    "    )\n",
    "    # pprint(res)\n",
    "\n",
    "    answer, score = \"idk\", 1.0\n",
    "\n",
    "    # Get the result\n",
    "    if res and isinstance(res, dict):\n",
    "        answer = res.get(\"answer\", \"idk\")\n",
    "        score = res.get(\"score\", 1.0)\n",
    "\n",
    "    answer = answer.strip()\n",
    "    score = round(score, 3)\n",
    "\n",
    "    print(f\"A: {answer} (score: {round(score, 3)})\")\n",
    "    # display(Markdown(f\"**A:** {answer} (score: {score})\"))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def run_models(question: str, context: str, models: list[str], **kwargs):\n",
    "    for model in models:\n",
    "        run(question, context, model=model, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Prompt Interface\n",
    "\n",
    "Models: https://huggingface.co/models?pipeline_tag=question-answering&sort=trending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ctx = \"\"\"\n",
    "Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
    "his hypodermic syringe from its neat morocco case. With his long,\n",
    "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
    "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
    "upon the sinewy forearm and wrist all dotted and scarred with\n",
    "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
    "pressed down the tiny piston, and sank back into the velvet-lined\n",
    "arm-chair with a long sigh of satisfaction.\n",
    "\"\"\"\n",
    "\n",
    "test_q = \"\"\"\n",
    "What's my name?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
      "his hypodermic syringe from its neat morocco case. With his long,\n",
      "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
      "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
      "upon the sinewy forearm and wrist all dotted and scarred with\n",
      "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
      "pressed down the tiny piston, and sank back into the velvet-lined\n",
      "arm-chair with a long sigh of satisfaction.\n",
      "Q: What's my name?\n",
      "A: Sherlock Holmes (score: 0.761)\n"
     ]
    }
   ],
   "source": [
    "# Default - \"distilbert-base-uncased-distilled-squad\"\n",
    "_ = run(test_q, test_ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: deepset/roberta-base-squad2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
      "his hypodermic syringe from its neat morocco case. With his long,\n",
      "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
      "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
      "upon the sinewy forearm and wrist all dotted and scarred with\n",
      "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
      "pressed down the tiny piston, and sank back into the velvet-lined\n",
      "arm-chair with a long sigh of satisfaction.\n",
      "Q: What's my name?\n",
      "A: Sherlock Holmes (score: 0.114)\n"
     ]
    }
   ],
   "source": [
    "_ = run(test_q, test_ctx, model=\"deepset/roberta-base-squad2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
      "his hypodermic syringe from its neat morocco case. With his long,\n",
      "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
      "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
      "upon the sinewy forearm and wrist all dotted and scarred with\n",
      "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
      "pressed down the tiny piston, and sank back into the velvet-lined\n",
      "arm-chair with a long sigh of satisfaction.\n",
      "Q: What's my name?\n",
      "A: Sherlock Holmes (score: 0.99)\n",
      "====================================================================================================\n",
      "model: deepset/roberta-base-squad2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
      "his hypodermic syringe from its neat morocco case. With his long,\n",
      "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
      "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
      "upon the sinewy forearm and wrist all dotted and scarred with\n",
      "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
      "pressed down the tiny piston, and sank back into the velvet-lined\n",
      "arm-chair with a long sigh of satisfaction.\n",
      "Q: What's my name?\n",
      "A: Sherlock Holmes (score: 0.114)\n"
     ]
    }
   ],
   "source": [
    "run_models(\n",
    "    test_q,\n",
    "    test_ctx,\n",
    "    models=[\n",
    "        \"distilbert-base-uncased-distilled-squad\",\n",
    "        \"deepset/roberta-base-squad2\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Experiments & Results\n",
    "\n",
    "For the first part, use the Hugging Face question-answering pipeline and feed it with the five 300-word long sections from the book of your choice that you analyzed in Project 1.\n",
    "\n",
    "These sections should be selected so they are: **introducing the protagonist(s), the antagonist, the crime and crime scene, any significant evidence, and the resolution of the crime/a narrative that presents the case against the perpetrator.**\n",
    "\n",
    "The questions you should ask are about the identity and characteristics of the protagonist, antagonist/perpetrator, the nature and the setting of the crime or crime scene, the evidence, and the case against the perpetrator.\n",
    "\n",
    "Document the questions, ask the questions, and document the specificity and accuracy of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try out a good selection of models and keep some interesting ones\n",
    "models = [\n",
    "    \"distilbert-base-uncased-distilled-squad\",\n",
    "    \"deepset/roberta-base-squad2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"\"\"\n",
    "My name Jeff.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.987)\n",
      "====================================================================================================\n",
      "model: deepset/roberta-base-squad2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.641)\n"
     ]
    }
   ],
   "source": [
    "s1q1 = \"\"\"\n",
    "What's my name?\n",
    "\"\"\"\n",
    "\n",
    "run_models(s1q1, s1, models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more cells and ask more questions on Section 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: document the specificity and accuracy of the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = \"\"\"\n",
    "My name Jeff.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.987)\n",
      "====================================================================================================\n",
      "model: deepset/roberta-base-squad2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.641)\n"
     ]
    }
   ],
   "source": [
    "s2q1 = \"\"\"\n",
    "What's my name?\n",
    "\"\"\"\n",
    "\n",
    "run_models(s2q1, s2, models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more cells and ask more questions on Section 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: document the specificity and accuracy of the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"\"\"\n",
    "My name Jeff.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.987)\n",
      "====================================================================================================\n",
      "model: deepset/roberta-base-squad2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.641)\n"
     ]
    }
   ],
   "source": [
    "s3q1 = \"\"\"\n",
    "What's my name?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "run_models(s3q1, s3, models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more cells and ask more questions on Section 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: document the specificity and accuracy of the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = \"\"\"\n",
    "My name Jeff.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.987)\n",
      "====================================================================================================\n",
      "model: deepset/roberta-base-squad2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.641)\n"
     ]
    }
   ],
   "source": [
    "s4q1 = \"\"\"\n",
    "What's my name?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "run_models(s4q1, s4, models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more cells and ask more questions on Section 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: document the specificity and accuracy of the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = \"\"\"\n",
    "My name Jeff.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.987)\n",
      "====================================================================================================\n",
      "model: deepset/roberta-base-squad2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "C: My name Jeff.\n",
      "Q: What's my name?\n",
      "A: Jeff (score: 0.641)\n"
     ]
    }
   ],
   "source": [
    "s5q1 = \"\"\"\n",
    "What's my name?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "run_models(s5q1, s5, models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more cells and ask more questions on Section 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: document the specificity and accuracy of the results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
