{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Question Answering\n",
    "\n",
    "For the first part, use the Hugging Face question-answering pipeline and feed it with the five 300-word long sections from the book of your choice that you analyzed in Project 1.\n",
    "\n",
    "These sections should be selected so they are: introducing the protagonist(s), the antagonist, the crime and crime scene, any significant evidence, and the resolution of the crime/a narrative that presents the case against the perpetrator.\n",
    "\n",
    "For a prompt, Implement a simple prompt interface that takes in your question, runs it against the model, and returns the answer. You don't need to do anything special about this, just a simple console I/O interface without any complicated error handling. It is up to you how you want to upload the context to the model (pre-loaded into your program, on-demand, etc.).\n",
    "\n",
    "The questions you should ask are about the identity and characteristics of the protagonist, antagonist/perpetrator, the nature and the setting of the crime or crime scene, the evidence, and the case against the perpetrator.\n",
    "\n",
    "Document the questions, ask the questions, and document the specificity and accuracy of the results.\n",
    "\n",
    "Part 1.2 - use two different HF QA models: use the default question-answering pipeline, then use other models of choice and discuss the differences in the result.\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "https://huggingface.co/docs/transformers/v4.35.0/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: matplotlib==3.8.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (3.8.2)\n",
      "Requirement already satisfied: spacy==3.7.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (3.7.2)\n",
      "Requirement already satisfied: torch==2.1.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (4.66.1)\n",
      "Requirement already satisfied: transformers==4.35.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (4.35.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.99 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (0.1.99)\n",
      "Requirement already satisfied: sacremoses==0.1.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (0.1.1)\n",
      "Requirement already satisfied: termcolor==2.3.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: evaluate==0.4.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (0.4.1)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (4.45.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: pillow>=8 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (10.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.4.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (6.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (59.6.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (0.3.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (8.2.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.5.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (1.0.10)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (11.0.2.54)\n",
      "Requirement already satisfied: fsspec in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (10.3.2.106)\n",
      "Requirement already satisfied: typing-extensions in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: filelock in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (8.9.2.26)\n",
      "Requirement already satisfied: triton==2.1.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.3.1)\n",
      "Requirement already satisfied: sympy in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (2023.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (0.17.3)\n",
      "Requirement already satisfied: click in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from sacremoses==0.1.1->-r ../requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from sacremoses==0.1.1->-r ../requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: pandas in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (3.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (2.14.7)\n",
      "Requirement already satisfied: multiprocess in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (0.70.15)\n",
      "Requirement already satisfied: dill in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (0.3.7)\n",
      "Requirement already satisfied: responses<0.19 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (0.18.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1->-r ../requirements.txt (line 3)) (12.3.101)\n",
      "Requirement already satisfied: aiohttp in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (3.9.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (0.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (14.0.1)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->-r ../requirements.txt (line 2)) (2.14.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->-r ../requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.8.2->-r ../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->-r ../requirements.txt (line 2)) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->-r ../requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from jinja2->spacy==3.7.2->-r ../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from pandas->evaluate==0.4.1->-r ../requirements.txt (line 10)) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from pandas->evaluate==0.4.1->-r ../requirements.txt (line 10)) (2023.3.post1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from sympy->torch==2.1.1->-r ../requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (1.9.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ../requirements.txt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from src import utils\n",
    "from src.question_answering import run_qa, run_qa_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Experiments & Results\n",
    "\n",
    "For the first part, use the Hugging Face question-answering pipeline and feed it with the five 300-word long sections from the book of your choice that you analyzed in Project 1.\n",
    "\n",
    "These sections should be selected so they are: **introducing the protagonist(s), the antagonist, the crime and crime scene, any significant evidence, and the resolution of the crime/a narrative that presents the case against the perpetrator.**\n",
    "\n",
    "The questions you should ask are about the identity and characteristics of the protagonist, antagonist/perpetrator, the nature and the setting of the crime or crime scene, the evidence, and the case against the perpetrator.\n",
    "\n",
    "Document the questions, ask the questions, and document the specificity and accuracy of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    # DistilBERT\n",
    "    \"distilbert-base-cased-distilled-squad\",\n",
    "    \"distilbert-base-uncased-distilled-squad\",\n",
    "    # RoBERTa\n",
    "    \"deepset/roberta-base-squad2\",\n",
    "    \"deepset/roberta-large-squad2\",\n",
    "    # Deberta\n",
    "    \"deepset/deberta-v3-base-squad2\",\n",
    "    \"deepset/deberta-v3-large-squad2\",\n",
    "    # Electra\n",
    "    \"deepset/electra-base-squad2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: ['protagonist.0.md', 'protagonist.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "Sherlock Holmes took his bottle from the corner of the mantel-piece and his hypodermic syringe from its neat morocco case. With his long, white, nervous fingers he adjusted the delicate needle, and rolled back his left shirt-cuff. For some little time his eyes rested thoughtfully upon the sinewy forearm and wrist all dotted and scarred with innumerable puncture-marks. Finally he thrust the sharp point home, pressed down the tiny piston, and sank back into the velvet-lined arm-chair with a long sigh of satisfaction. Three times a day for many months I had witnessed this performance, but custom had not reconciled my mind to it. On the contrary, from day to day I had become more irritable at the sight, and my conscience swelled nightly within me at the thought that I had lacked the courage to protest. Again and again I had registered a vow that I should deliver my soul upon the subject, but there was that in the cool, nonchalant air of my companion which made him the last man with whom one would care to take anything approaching to a liberty. His great powers, his masterly manner, and the experience which I had had of his many extraordinary qualities, all made me diffident and backward in crossing him. Yet upon that afternoon, whether it was the Beaune which I had taken with my lunch, or the additional exasperation produced by the extreme deliberation of his manner, I suddenly felt that I could hold out no longer. \"Which is it to-day?\" I asked,-\"morphine or cocaine?\" He raised his eyes languidly from the old black-letter volume which he had opened. \"It is cocaine,\" he said,-\"a seven-per-cent. solution. Would you care to try it?\" \"No, indeed,\" I answered, brusquely. \"My constitution has not got over the Afghan campaign yet. I\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the main character that the story revolves around?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: Beaune (model confidence score: 0.465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/scratchbooks/src/utils.py:90: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  score = doc1.similarity(doc2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bertscore_f1': 0.49433884024620056,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.464594304561615,\n",
      " 'bertscore_recall': 0.5281525254249573,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: the Beaune (model confidence score: 0.588)\n",
      "{'bertscore_f1': 0.49187344312667847,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.48016396164894104,\n",
      " 'bertscore_recall': 0.5041683316230774,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: cocaine (model confidence score: 0.153)\n",
      "{'bertscore_f1': 0.5859436988830566,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6038551926612854,\n",
      " 'bertscore_recall': 0.5690641403198242,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.10666643400956173}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: Sherlock Holmes (model confidence score: 0.865)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: Sherlock Holmes (model confidence score: 0.864)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: Sherlock Holmes (model confidence score: 0.991)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: It is cocaine (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.4590016007423401,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4671434462070465,\n",
      " 'bertscore_recall': 0.4511386752128601,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.10666643400956173}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the detective in the story?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.989)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.866)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.478)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.986)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 1.0)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.995)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who is the detective in the story?\n",
      "A: It is cocaine (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.4590016007423401,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4671434462070465,\n",
      " 'bertscore_recall': 0.4511386752128601,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.10666643400956173}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the main protagonist in the story?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.843)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.782)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: cocaine (model confidence score: 0.101)\n",
      "{'bertscore_f1': 0.5859436988830566,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6038551926612854,\n",
      " 'bertscore_recall': 0.5690641403198242,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.10666643400956173}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.964)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.949)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.989)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: It is cocaine (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.4590016007423401,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4671434462070465,\n",
      " 'bertscore_recall': 0.4511386752128601,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.10666643400956173}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What did Holmes take from the morocco case?\n",
      "Expected Answer: Syringe\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What did Holmes take from the morocco case?\n",
      "A: hypodermic syringe (model confidence score: 0.489)\n",
      "{'bertscore_f1': 0.7596561908721924,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6908412575721741,\n",
      " 'bertscore_recall': 0.843697190284729,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.938364181772037}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What did Holmes take from the morocco case?\n",
      "A: hypodermic syringe (model confidence score: 0.169)\n",
      "{'bertscore_f1': 0.7596561908721924,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6908412575721741,\n",
      " 'bertscore_recall': 0.843697190284729,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.938364181772037}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What did Holmes take from the morocco case?\n",
      "A: hypodermic syringe (model confidence score: 0.395)\n",
      "{'bertscore_f1': 0.7596561908721924,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6908412575721741,\n",
      " 'bertscore_recall': 0.843697190284729,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.938364181772037}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What did Holmes take from the morocco case?\n",
      "A: hypodermic syringe (model confidence score: 0.688)\n",
      "{'bertscore_f1': 0.7596561908721924,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6908412575721741,\n",
      " 'bertscore_recall': 0.843697190284729,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.938364181772037}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What did Holmes take from the morocco case?\n",
      "A: hypodermic syringe (model confidence score: 0.639)\n",
      "{'bertscore_f1': 0.7596561908721924,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6908412575721741,\n",
      " 'bertscore_recall': 0.843697190284729,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.938364181772037}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What did Holmes take from the morocco case?\n",
      "A: hypodermic syringe (model confidence score: 0.654)\n",
      "{'bertscore_f1': 0.7596561908721924,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6908412575721741,\n",
      " 'bertscore_recall': 0.843697190284729,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.938364181772037}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What did Holmes take from the morocco case?\n",
      "A: his hypodermic syringe (model confidence score: 0.778)\n",
      "{'bertscore_f1': 0.666911780834198,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6225039958953857,\n",
      " 'bertscore_recall': 0.7181421518325806,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.938364181772037}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What was noticeable about Holmes' forearm and wrist?\n",
      "Expected Answer: Puncture-marks\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What was noticeable about Holmes' forearm and wrist?\n",
      "A: cocaine (model confidence score: 0.157)\n",
      "{'bertscore_f1': 0.5514916181564331,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.533843994140625,\n",
      " 'bertscore_recall': 0.5703458786010742,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.055670596167740415}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What was noticeable about Holmes' forearm and wrist?\n",
      "A: puncture-marks (model confidence score: 0.278)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What was noticeable about Holmes' forearm and wrist?\n",
      "A: dotted and scarred with innumerable puncture-marks (model confidence score: 0.451)\n",
      "{'bertscore_f1': 0.689240038394928,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6137482523918152,\n",
      " 'bertscore_recall': 0.7859076857566833,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.8586987364487958}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What was noticeable about Holmes' forearm and wrist?\n",
      "A: innumerable puncture-marks (model confidence score: 0.415)\n",
      "{'bertscore_f1': 0.7874923944473267,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.736612856388092,\n",
      " 'bertscore_recall': 0.8459222912788391,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 0.9593498319928196}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What was noticeable about Holmes' forearm and wrist?\n",
      "A: sinewy forearm and wrist all dotted and scarred with innumerable puncture-marks. (model confidence score: 0.454)\n",
      "{'bertscore_f1': 0.6442822217941284,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5631415247917175,\n",
      " 'bertscore_recall': 0.7527414560317993,\n",
      " 'rouge1': 0.2857142857142857,\n",
      " 'rouge2': 0.16666666666666669,\n",
      " 'rougeL': 0.2857142857142857,\n",
      " 'rougeLsum': 0.2857142857142857,\n",
      " 'spacy_sim': 0.8122866809643169}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What was noticeable about Holmes' forearm and wrist?\n",
      "A: dotted and scarred with innumerable puncture-marks. (model confidence score: 0.607)\n",
      "{'bertscore_f1': 0.7011342644691467,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6324737668037415,\n",
      " 'bertscore_recall': 0.7865175604820251,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.8586987364487958}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What was noticeable about Holmes' forearm and wrist?\n",
      "A: puncture-marks (model confidence score: 0.999)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Describe Holmes' manner while preparing the injection.\n",
      "Expected Answer: Nonchalant\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Describe Holmes' manner while preparing the injection.\n",
      "A: Beaune (model confidence score: 0.064)\n",
      "{'bertscore_f1': 0.37855976819992065,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.3720930814743042,\n",
      " 'bertscore_recall': 0.38525521755218506,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Describe Holmes' manner while preparing the injection.\n",
      "A: masterly (model confidence score: 0.325)\n",
      "{'bertscore_f1': 0.3967536389827728,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5130576491355896,\n",
      " 'bertscore_recall': 0.3234347999095917,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.21111524976404802}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Describe Holmes' manner while preparing the injection.\n",
      "A: cocaine (model confidence score: 0.229)\n",
      "{'bertscore_f1': 0.4062938690185547,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.40654098987579346,\n",
      " 'bertscore_recall': 0.4060470461845398,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.13025393423064338}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Describe Holmes' manner while preparing the injection.\n",
      "A: With his long, white, nervous fingers he adjusted the delicate needle (model confidence score: 0.183)\n",
      "{'bertscore_f1': 0.40816348791122437,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.40705710649490356,\n",
      " 'bertscore_recall': 0.40927591919898987,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2710701090945207}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Describe Holmes' manner while preparing the injection.\n",
      "A: extreme deliberation (model confidence score: 0.772)\n",
      "{'bertscore_f1': 0.4590533673763275,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5398765206336975,\n",
      " 'bertscore_recall': 0.3992786109447479,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.21779917831735085}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Describe Holmes' manner while preparing the injection.\n",
      "A: extreme deliberation (model confidence score: 0.229)\n",
      "{'bertscore_f1': 0.4590533673763275,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5398765206336975,\n",
      " 'bertscore_recall': 0.3992786109447479,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.21779917831735085}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Describe Holmes' manner while preparing the injection.\n",
      "A: masterly manner (model confidence score: 0.907)\n",
      "{'bertscore_f1': 0.47628259658813477,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4987417459487915,\n",
      " 'bertscore_recall': 0.4557589888572693,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.29421843671699066}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What substance did Holmes use that day?\n",
      "Expected Answer: Cocaine\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What substance did Holmes use that day?\n",
      "A: cocaine (model confidence score: 0.931)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What substance did Holmes use that day?\n",
      "A: cocaine (model confidence score: 0.661)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What substance did Holmes use that day?\n",
      "A: morphine or cocaine (model confidence score: 0.195)\n",
      "{'bertscore_f1': 0.7077434062957764,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6796058416366577,\n",
      " 'bertscore_recall': 0.7383115291595459,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9048151104014313}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What substance did Holmes use that day?\n",
      "A: cocaine (model confidence score: 0.461)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What substance did Holmes use that day?\n",
      "A: cocaine,\" (model confidence score: 0.99)\n",
      "{'bertscore_f1': 0.8524715900421143,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.802142858505249,\n",
      " 'bertscore_recall': 0.909538745880127,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What substance did Holmes use that day?\n",
      "A: cocaine,\" (model confidence score: 0.692)\n",
      "{'bertscore_f1': 0.8524715900421143,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.802142858505249,\n",
      " 'bertscore_recall': 0.909538745880127,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What substance did Holmes use that day?\n",
      "A: morphine or cocaine (model confidence score: 0.771)\n",
      "{'bertscore_f1': 0.7077434062957764,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6796058416366577,\n",
      " 'bertscore_recall': 0.7383115291595459,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9048151104014313}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What emotion does the narrator feel towards Holmes' habit?\n",
      "Expected Answer: Irritation\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What emotion does the narrator feel towards Holmes' habit?\n",
      "A: cocaine (model confidence score: 0.123)\n",
      "{'bertscore_f1': 0.5251383185386658,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5366315841674805,\n",
      " 'bertscore_recall': 0.5141270160675049,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.12850644183682308}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What emotion does the narrator feel towards Holmes' habit?\n",
      "A: cocaine (model confidence score: 0.185)\n",
      "{'bertscore_f1': 0.5251383185386658,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5366315841674805,\n",
      " 'bertscore_recall': 0.5141270160675049,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.12850644183682308}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What emotion does the narrator feel towards Holmes' habit?\n",
      "A: cocaine (model confidence score: 0.226)\n",
      "{'bertscore_f1': 0.5251383185386658,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5366315841674805,\n",
      " 'bertscore_recall': 0.5141270160675049,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.12850644183682308}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What emotion does the narrator feel towards Holmes' habit?\n",
      "A: irritable (model confidence score: 0.755)\n",
      "{'bertscore_f1': 0.8308284878730774,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8308284878730774,\n",
      " 'bertscore_recall': 0.8308284878730774,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.7053101909462468}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What emotion does the narrator feel towards Holmes' habit?\n",
      "A: cocaine,\" (model confidence score: 0.397)\n",
      "{'bertscore_f1': 0.48692163825035095,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.49763309955596924,\n",
      " 'bertscore_recall': 0.4766615629196167,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.12850644183682308}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What emotion does the narrator feel towards Holmes' habit?\n",
      "A: exasperation (model confidence score: 0.719)\n",
      "{'bertscore_f1': 0.9029618501663208,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9029618501663208,\n",
      " 'bertscore_recall': 0.9029618501663208,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.758801817943644}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What emotion does the narrator feel towards Holmes' habit?\n",
      "A: \" (model confidence score: 0.007)\n",
      "{'bertscore_f1': 0.35094889998435974,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4514206051826477,\n",
      " 'bertscore_recall': 0.28705883026123047,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What made the narrator more irritable over time?\n",
      "Expected Answer: Holmes' habit\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What made the narrator more irritable over time?\n",
      "A: extreme deliberation (model confidence score: 0.281)\n",
      "{'bertscore_f1': 0.5420380234718323,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5688831806182861,\n",
      " 'bertscore_recall': 0.5176122784614563,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.24739153747640005}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What made the narrator more irritable over time?\n",
      "A: from day to day (model confidence score: 0.358)\n",
      "{'bertscore_f1': 0.4687923789024353,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.45862865447998047,\n",
      " 'bertscore_recall': 0.47941678762435913,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.1676126123711238}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What made the narrator more irritable over time?\n",
      "A: extreme deliberation of his manner (model confidence score: 0.136)\n",
      "{'bertscore_f1': 0.5430848598480225,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5107643604278564,\n",
      " 'bertscore_recall': 0.5797721743583679,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.31481013045502526}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What made the narrator more irritable over time?\n",
      "A: Sherlock Holmes (model confidence score: 0.322)\n",
      "{'bertscore_f1': 0.5875648856163025,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5778283476829529,\n",
      " 'bertscore_recall': 0.5976350903511047,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.3614692119752116}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What made the narrator more irritable over time?\n",
      "A: extreme deliberation of his manner, (model confidence score: 0.132)\n",
      "{'bertscore_f1': 0.5410405397415161,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5369124412536621,\n",
      " 'bertscore_recall': 0.5452326536178589,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.31481013045502526}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What made the narrator more irritable over time?\n",
      "A: I had become more irritable at the sight, (model confidence score: 0.077)\n",
      "{'bertscore_f1': 0.5235210061073303,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5244554281234741,\n",
      " 'bertscore_recall': 0.5225899815559387,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.412709188668778}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What made the narrator more irritable over time?\n",
      "A: extreme deliberation of his manner (model confidence score: 0.812)\n",
      "{'bertscore_f1': 0.5430848598480225,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5107643604278564,\n",
      " 'bertscore_recall': 0.5797721743583679,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.31481013045502526}\n",
      "Found: ['antagonist.0.md', 'antagonist.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "His name, I have every reason to believe, is Jonathan Small. He is a poorly-educated man, small, active, with his right leg off, and wearing a wooden stump which is worn away upon the inner side. His left boot has a coarse, square-toed sole, with an iron band round the heel. He is a middle-aged man, much sunburned, and has been a convict. These few indications may be of some assistance to you, coupled with the fact that there is a good deal of skin missing from the palm of his hand. The other man-\" \"Ah! the other man-?\" asked Athelney Jones, in a sneering voice, but impressed none the less, as I could easily see, by the precision of the other's manner. \"Is a rather curious person,\" said Sherlock Holmes, turning upon his heel. \"I hope before very long to be able to introduce you to the pair of them.-A word with you, Watson.\" He led me out to the head of the stair. \"This unexpected occurrence,\" he said, \"has caused us rather to lose sight of the original purpose of our journey.\" \"I have just been thinking so,\" I answered. \"It is not right that Miss Morstan should remain in this stricken house.\" \"No. You must escort her home. She lives with Mrs. Cecil Forrester, in Lower Camberwell: so it is not very far. I will wait for you here if you will drive out again. Or perhaps you are too tired?\" \"By no means. I don't think I could rest until I know more of this fantastic business. I have seen something of the rough side of life, but I give you my word that this quick succession of strange surprises to-night has shaken my nerve completely. I should like, however, to see the matter through with\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the primary antagonist or perpetrator in the story?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who is the primary antagonist or perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.841)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who is the primary antagonist or perpetrator in the story?\n",
      "A: Miss Morstan (model confidence score: 0.822)\n",
      "{'bertscore_f1': 0.3868972361087799,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4046817421913147,\n",
      " 'bertscore_recall': 0.3706100583076477,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': -0.005961746669993993}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who is the primary antagonist or perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.044)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the primary antagonist or perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.943)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who is the primary antagonist or perpetrator in the story?\n",
      "A: Athelney Jones, (model confidence score: 0.977)\n",
      "{'bertscore_f1': 0.658448338508606,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6605764627456665,\n",
      " 'bertscore_recall': 0.656333863735199,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.25907327308965244}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who is the primary antagonist or perpetrator in the story?\n",
      "A: Jonathan Small. (model confidence score: 0.299)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who is the primary antagonist or perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.001)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the perpetrator in the story?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who is the perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.843)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who is the perpetrator in the story?\n",
      "A: Miss Morstan (model confidence score: 0.772)\n",
      "{'bertscore_f1': 0.3868972361087799,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4046817421913147,\n",
      " 'bertscore_recall': 0.3706100583076477,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': -0.005961746669993993}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who is the perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.5)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.979)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who is the perpetrator in the story?\n",
      "A: Jonathan Small. (model confidence score: 0.944)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who is the perpetrator in the story?\n",
      "A: Jonathan Small. (model confidence score: 0.626)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who is the perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.0)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the person responsible for the crime?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who is the person responsible for the crime?\n",
      "A: Jonathan Small (model confidence score: 0.89)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who is the person responsible for the crime?\n",
      "A: Jonathan Small (model confidence score: 0.681)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who is the person responsible for the crime?\n",
      "A: Jonathan Small (model confidence score: 0.644)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the person responsible for the crime?\n",
      "A: Jonathan Small (model confidence score: 0.971)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who is the person responsible for the crime?\n",
      "A: Jonathan Small. (model confidence score: 0.967)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who is the person responsible for the crime?\n",
      "A: Jonathan Small. (model confidence score: 0.156)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who is the person responsible for the crime?\n",
      "A: Jonathan Small (model confidence score: 0.0)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What was Jonathan Small's previous legal status?\n",
      "Expected Answer: Convict\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What was Jonathan Small's previous legal status?\n",
      "A: convict (model confidence score: 0.249)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What was Jonathan Small's previous legal status?\n",
      "A: convict (model confidence score: 0.52)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What was Jonathan Small's previous legal status?\n",
      "A: convict (model confidence score: 0.581)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What was Jonathan Small's previous legal status?\n",
      "A: convict (model confidence score: 0.675)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What was Jonathan Small's previous legal status?\n",
      "A: convict. (model confidence score: 0.923)\n",
      "{'bertscore_f1': 0.8697762489318848,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8369975090026855,\n",
      " 'bertscore_recall': 0.9052271246910095,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What was Jonathan Small's previous legal status?\n",
      "A: convict. (model confidence score: 0.549)\n",
      "{'bertscore_f1': 0.8697762489318848,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8369975090026855,\n",
      " 'bertscore_recall': 0.9052271246910095,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What was Jonathan Small's previous legal status?\n",
      "A: a convict (model confidence score: 0.677)\n",
      "{'bertscore_f1': 0.8070901036262512,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8070900440216064,\n",
      " 'bertscore_recall': 0.8070900440216064,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Which limb is missing from Jonathan Small's body?\n",
      "Expected Answer: Right leg\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Which limb is missing from Jonathan Small's body?\n",
      "A: right leg (model confidence score: 0.219)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Which limb is missing from Jonathan Small's body?\n",
      "A: right leg (model confidence score: 0.62)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Which limb is missing from Jonathan Small's body?\n",
      "A: right leg (model confidence score: 0.703)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Which limb is missing from Jonathan Small's body?\n",
      "A: right leg (model confidence score: 0.639)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Which limb is missing from Jonathan Small's body?\n",
      "A: right (model confidence score: 0.973)\n",
      "{'bertscore_f1': 0.46647483110427856,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5033541917800903,\n",
      " 'bertscore_recall': 0.4346306324005127,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.6425846907956433}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Which limb is missing from Jonathan Small's body?\n",
      "A: right leg (model confidence score: 0.737)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Which limb is missing from Jonathan Small's body?\n",
      "A: right leg (model confidence score: 0.999)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What physical disability does Jonathan Small have?\n",
      "Expected Answer: Right leg off\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What physical disability does Jonathan Small have?\n",
      "A: tired (model confidence score: 0.81)\n",
      "{'bertscore_f1': 0.37646302580833435,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.3889641761779785,\n",
      " 'bertscore_recall': 0.36474040150642395,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2788516394626354}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What physical disability does Jonathan Small have?\n",
      "A: tired (model confidence score: 0.75)\n",
      "{'bertscore_f1': 0.37646302580833435,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.3889641761779785,\n",
      " 'bertscore_recall': 0.36474040150642395,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2788516394626354}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What physical disability does Jonathan Small have?\n",
      "A: his right leg off (model confidence score: 0.271)\n",
      "{'bertscore_f1': 0.8117198944091797,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7762545943260193,\n",
      " 'bertscore_recall': 0.8505809903144836,\n",
      " 'rouge1': 0.8571428571428571,\n",
      " 'rouge2': 0.8,\n",
      " 'rougeL': 0.8571428571428571,\n",
      " 'rougeLsum': 0.8571428571428571,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What physical disability does Jonathan Small have?\n",
      "A: right leg off (model confidence score: 0.34)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What physical disability does Jonathan Small have?\n",
      "A: a wooden stump which is worn away upon the inner side. (model confidence score: 0.163)\n",
      "{'bertscore_f1': 0.48350268602371216,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4977417588233948,\n",
      " 'bertscore_recall': 0.47005563974380493,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.5012911630482216}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What physical disability does Jonathan Small have?\n",
      "A: his right leg off, (model confidence score: 0.34)\n",
      "{'bertscore_f1': 0.7677716612815857,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7356176376342773,\n",
      " 'bertscore_recall': 0.8028651475906372,\n",
      " 'rouge1': 0.8571428571428571,\n",
      " 'rouge2': 0.8,\n",
      " 'rougeL': 0.8571428571428571,\n",
      " 'rougeLsum': 0.8571428571428571,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What physical disability does Jonathan Small have?\n",
      "A: His left boot has a coarse, square-toed sole (model confidence score: 0.095)\n",
      "{'bertscore_f1': 0.4634610712528229,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4691733121871948,\n",
      " 'bertscore_recall': 0.4578862190246582,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.5233735694446151}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What is the condition of Jonathan Small's wooden stump?\n",
      "Expected Answer: Worn away\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What is the condition of Jonathan Small's wooden stump?\n",
      "A: worn away upon the inner side (model confidence score: 0.864)\n",
      "{'bertscore_f1': 0.7328334450721741,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6570538878440857,\n",
      " 'bertscore_recall': 0.8283714652061462,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9144565901296556}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What is the condition of Jonathan Small's wooden stump?\n",
      "A: tired (model confidence score: 0.453)\n",
      "{'bertscore_f1': 0.604508101940155,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6196984052658081,\n",
      " 'bertscore_recall': 0.5900447964668274,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.37302394700395164}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What is the condition of Jonathan Small's wooden stump?\n",
      "A: worn away upon the inner side (model confidence score: 0.603)\n",
      "{'bertscore_f1': 0.7328334450721741,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6570538878440857,\n",
      " 'bertscore_recall': 0.8283714652061462,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9144565901296556}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What is the condition of Jonathan Small's wooden stump?\n",
      "A: worn away upon the inner side (model confidence score: 0.907)\n",
      "{'bertscore_f1': 0.7328334450721741,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6570538878440857,\n",
      " 'bertscore_recall': 0.8283714652061462,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9144565901296556}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What is the condition of Jonathan Small's wooden stump?\n",
      "A: worn away upon the inner side. (model confidence score: 0.997)\n",
      "{'bertscore_f1': 0.7298429608345032,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6541337370872498,\n",
      " 'bertscore_recall': 0.8253709077835083,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9144565901296556}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What is the condition of Jonathan Small's wooden stump?\n",
      "A: worn away upon the inner side. (model confidence score: 0.909)\n",
      "{'bertscore_f1': 0.7298429608345032,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6541337370872498,\n",
      " 'bertscore_recall': 0.8253709077835083,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9144565901296556}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What is the condition of Jonathan Small's wooden stump?\n",
      "A: worn away upon the inner side (model confidence score: 0.984)\n",
      "{'bertscore_f1': 0.7328334450721741,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6570538878440857,\n",
      " 'bertscore_recall': 0.8283714652061462,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9144565901296556}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What is the condition of Small's hand?\n",
      "Expected Answer: Missing skin\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What is the condition of Small's hand?\n",
      "A: tired (model confidence score: 0.442)\n",
      "{'bertscore_f1': 0.3883044123649597,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.410691499710083,\n",
      " 'bertscore_recall': 0.3682318329811096,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2817159267073335}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What is the condition of Small's hand?\n",
      "A: tired (model confidence score: 0.674)\n",
      "{'bertscore_f1': 0.3883044123649597,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.410691499710083,\n",
      " 'bertscore_recall': 0.3682318329811096,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2817159267073335}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What is the condition of Small's hand?\n",
      "A: skin missing (model confidence score: 0.179)\n",
      "{'bertscore_f1': 0.8073031902313232,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8073031902313232,\n",
      " 'bertscore_recall': 0.8073031902313232,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 1.000000031051118}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What is the condition of Small's hand?\n",
      "A: there is a good deal of skin missing from the palm of his hand (model confidence score: 0.291)\n",
      "{'bertscore_f1': 0.5884615182876587,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5076013803482056,\n",
      " 'bertscore_recall': 0.6999648809432983,\n",
      " 'rouge1': 0.25,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.125,\n",
      " 'rougeLsum': 0.125,\n",
      " 'spacy_sim': 0.7664694971682984}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What is the condition of Small's hand?\n",
      "A: skin missing (model confidence score: 0.319)\n",
      "{'bertscore_f1': 0.8073031902313232,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8073031902313232,\n",
      " 'bertscore_recall': 0.8073031902313232,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 1.000000031051118}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What is the condition of Small's hand?\n",
      "A: a good deal of skin missing from the palm of his hand. (model confidence score: 0.167)\n",
      "{'bertscore_f1': 0.6287155747413635,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5650306344032288,\n",
      " 'bertscore_recall': 0.7085800170898438,\n",
      " 'rouge1': 0.2857142857142857,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.14285714285714285,\n",
      " 'rougeLsum': 0.14285714285714285,\n",
      " 'spacy_sim': 0.7664694971682984}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What is the condition of Small's hand?\n",
      "A: skin missing (model confidence score: 0.945)\n",
      "{'bertscore_f1': 0.8073031902313232,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8073031902313232,\n",
      " 'bertscore_recall': 0.8073031902313232,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 1.000000031051118}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What is missing from Jonathan Small's hand?\n",
      "Expected Answer: Skin on palm\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What is missing from Jonathan Small's hand?\n",
      "A: skin (model confidence score: 0.957)\n",
      "{'bertscore_f1': 0.6255573034286499,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6703099608421326,\n",
      " 'bertscore_recall': 0.5864064693450928,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8865567736112707}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What is missing from Jonathan Small's hand?\n",
      "A: skin (model confidence score: 0.692)\n",
      "{'bertscore_f1': 0.6255573034286499,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6703099608421326,\n",
      " 'bertscore_recall': 0.5864064693450928,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8865567736112707}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What is missing from Jonathan Small's hand?\n",
      "A: skin (model confidence score: 0.806)\n",
      "{'bertscore_f1': 0.6255573034286499,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6703099608421326,\n",
      " 'bertscore_recall': 0.5864064693450928,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8865567736112707}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What is missing from Jonathan Small's hand?\n",
      "A: skin (model confidence score: 0.786)\n",
      "{'bertscore_f1': 0.6255573034286499,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6703099608421326,\n",
      " 'bertscore_recall': 0.5864064693450928,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8865567736112707}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What is missing from Jonathan Small's hand?\n",
      "A: skin (model confidence score: 0.998)\n",
      "{'bertscore_f1': 0.6255573034286499,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6703099608421326,\n",
      " 'bertscore_recall': 0.5864064693450928,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8865567736112707}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What is missing from Jonathan Small's hand?\n",
      "A: skin (model confidence score: 0.561)\n",
      "{'bertscore_f1': 0.6255573034286499,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6703099608421326,\n",
      " 'bertscore_recall': 0.5864064693450928,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8865567736112707}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What is missing from Jonathan Small's hand?\n",
      "A: skin (model confidence score: 0.994)\n",
      "{'bertscore_f1': 0.6255573034286499,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6703099608421326,\n",
      " 'bertscore_recall': 0.5864064693450928,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8865567736112707}\n",
      "Found: ['crime.0.md', 'crime.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "\"We earned a living at this time by my exhibiting poor Tonga at fairs and other such places as the black cannibal. He would eat raw meat and dance his war-dance: so we always had a hatful of pennies after a day's work. I still heard all the news from Pondicherry Lodge, and for some years there was no news to hear, except that they were hunting for the treasure. At last, however, came what we had waited for so long. The treasure had been found. It was up at the top of the house, in Mr. Bartholomew Sholto's chemical laboratory. I came at once and had a look at the place, but I could not see how with my wooden leg I was to make my way up to it. I learned, however, about a trap-door in the roof, and also about Mr. Sholto's supper-hour. It seemed to me that I could manage the thing easily through Tonga. I brought him out with me with a long rope wound round his waist. He could climb like a cat, and he soon made his way through the roof, but, as ill luck would have it, Bartholomew Sholto was still in the room, to his cost. Tonga thought he had done something very clever in killing him, for when I came up by the rope I found him strutting about as proud as a peacock. Very much surprised was he when I made at him with the rope's end and cursed him for a little blood-thirsty imp. I took the treasure-box and let it down, and then slid down myself, having first left the sign of the four upon the table, to show that the jewels had come back at last to those who had most right to them. Tonga then\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What criminal activity took place?\n",
      "Expected Answer: Theft of a treasure\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What criminal activity took place?\n",
      "A: the black cannibal (model confidence score: 0.359)\n",
      "{'bertscore_f1': 0.515379011631012,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.48224538564682007,\n",
      " 'bertscore_recall': 0.5534015893936157,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.23828533004285166}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What criminal activity took place?\n",
      "A: black cannibal (model confidence score: 0.017)\n",
      "{'bertscore_f1': 0.4273728132247925,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.39258134365081787,\n",
      " 'bertscore_recall': 0.46893051266670227,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.23828533004285166}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What criminal activity took place?\n",
      "A: black cannibal (model confidence score: 0.034)\n",
      "{'bertscore_f1': 0.4273728132247925,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.39258134365081787,\n",
      " 'bertscore_recall': 0.46893051266670227,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.23828533004285166}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What criminal activity took place?\n",
      "A: black cannibal (model confidence score: 0.003)\n",
      "{'bertscore_f1': 0.4273728132247925,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.39258134365081787,\n",
      " 'bertscore_recall': 0.46893051266670227,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.23828533004285166}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What criminal activity took place?\n",
      "A: Bartholomew Sholto was still in the room, (model confidence score: 0.003)\n",
      "{'bertscore_f1': 0.4975390136241913,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.48146194219589233,\n",
      " 'bertscore_recall': 0.5147268772125244,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.09495317465214131}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What criminal activity took place?\n",
      "A: Tonga thought he had done something very clever in killing him, (model confidence score: 0.114)\n",
      "{'bertscore_f1': 0.5066315531730652,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.46454188227653503,\n",
      " 'bertscore_recall': 0.5571081042289734,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.38726694465011685}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What criminal activity took place?\n",
      "A: they were hunting for the treasure (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.680173397064209,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.668946385383606,\n",
      " 'bertscore_recall': 0.691783607006073,\n",
      " 'rouge1': 0.2,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.2,\n",
      " 'rougeLsum': 0.2,\n",
      " 'spacy_sim': 0.5971644600197508}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Where was the treasure found?\n",
      "Expected Answer: Chemical laboratory\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Where was the treasure found?\n",
      "A: Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.527)\n",
      "{'bertscore_f1': 0.6112869381904602,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4785822927951813,\n",
      " 'bertscore_recall': 0.8458225727081299,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Where was the treasure found?\n",
      "A: Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.178)\n",
      "{'bertscore_f1': 0.6112869381904602,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4785822927951813,\n",
      " 'bertscore_recall': 0.8458225727081299,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Where was the treasure found?\n",
      "A: Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.261)\n",
      "{'bertscore_f1': 0.6112869381904602,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4785822927951813,\n",
      " 'bertscore_recall': 0.8458225727081299,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Where was the treasure found?\n",
      "A: in Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.235)\n",
      "{'bertscore_f1': 0.572414219379425,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4461829960346222,\n",
      " 'bertscore_recall': 0.7982498407363892,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Where was the treasure found?\n",
      "A: in Mr. Bartholomew Sholto's chemical laboratory. (model confidence score: 0.676)\n",
      "{'bertscore_f1': 0.6009104251861572,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4819699227809906,\n",
      " 'bertscore_recall': 0.7977885603904724,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Where was the treasure found?\n",
      "A: in Mr. Bartholomew Sholto's chemical laboratory. (model confidence score: 0.232)\n",
      "{'bertscore_f1': 0.6009104251861572,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4819699227809906,\n",
      " 'bertscore_recall': 0.7977885603904724,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Where was the treasure found?\n",
      "A: in Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.9)\n",
      "{'bertscore_f1': 0.572414219379425,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4461829960346222,\n",
      " 'bertscore_recall': 0.7982498407363892,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Where did the crime take place\n",
      "Expected Answer: Chemical laboratory\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Where did the crime take place\n",
      "A: Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.043)\n",
      "{'bertscore_f1': 0.6112869381904602,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4785822927951813,\n",
      " 'bertscore_recall': 0.8458225727081299,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Where did the crime take place\n",
      "A: Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.02)\n",
      "{'bertscore_f1': 0.6112869381904602,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4785822927951813,\n",
      " 'bertscore_recall': 0.8458225727081299,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Where did the crime take place\n",
      "A: Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.01)\n",
      "{'bertscore_f1': 0.6112869381904602,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4785822927951813,\n",
      " 'bertscore_recall': 0.8458225727081299,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Where did the crime take place\n",
      "A: Pondicherry Lodge (model confidence score: 0.025)\n",
      "{'bertscore_f1': 0.5715089440345764,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5792762041091919,\n",
      " 'bertscore_recall': 0.5639472603797913,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0041812132145634985}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Where did the crime take place\n",
      "A: Bartholomew Sholto was still in the room, (model confidence score: 0.741)\n",
      "{'bertscore_f1': 0.436102956533432,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4402273893356323,\n",
      " 'bertscore_recall': 0.43205511569976807,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.15477019441913945}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Where did the crime take place\n",
      "A: in Mr. Bartholomew Sholto's chemical laboratory. (model confidence score: 0.13)\n",
      "{'bertscore_f1': 0.6009104251861572,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4819699227809906,\n",
      " 'bertscore_recall': 0.7977885603904724,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Where did the crime take place\n",
      "A: in Mr. Bartholomew Sholto's chemical laboratory. (model confidence score: 0.018)\n",
      "{'bertscore_f1': 0.6009104251861572,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4819699227809906,\n",
      " 'bertscore_recall': 0.7977885603904724,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: How did Tonga access the roof?\n",
      "Expected Answer: Trap-door\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: How did Tonga access the roof?\n",
      "A: trap-door (model confidence score: 0.57)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: How did Tonga access the roof?\n",
      "A: trap-door (model confidence score: 0.07)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: How did Tonga access the roof?\n",
      "A: trap-door (model confidence score: 0.384)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: How did Tonga access the roof?\n",
      "A: a long rope wound round his waist (model confidence score: 0.591)\n",
      "{'bertscore_f1': 0.5500807762145996,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4896923005580902,\n",
      " 'bertscore_recall': 0.627458393573761,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.38928000231795745}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: How did Tonga access the roof?\n",
      "A: with a long rope wound round his waist. (model confidence score: 0.257)\n",
      "{'bertscore_f1': 0.6006685495376587,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5759766101837158,\n",
      " 'bertscore_recall': 0.6275723576545715,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.38928000231795745}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: How did Tonga access the roof?\n",
      "A: He could climb like a cat, (model confidence score: 0.285)\n",
      "{'bertscore_f1': 0.6252719163894653,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6350018978118896,\n",
      " 'bertscore_recall': 0.6158355474472046,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.4276706209404271}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: How did Tonga access the roof?\n",
      "A: trap-door (model confidence score: 0.935)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What hindered Jonathan's access to the treasure?\n",
      "Expected Answer: Wooden leg\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What hindered Jonathan's access to the treasure?\n",
      "A: the jewels had come back at last to those who had most right to them (model confidence score: 0.05)\n",
      "{'bertscore_f1': 0.4013935625553131,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.3156222105026245,\n",
      " 'bertscore_recall': 0.5511779189109802,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.22415456197080338}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What hindered Jonathan's access to the treasure?\n",
      "A: The treasure had been found. It was up at the top of the house (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.49613744020462036,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.42047417163848877,\n",
      " 'bertscore_recall': 0.6050069332122803,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.1892438672936832}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What hindered Jonathan's access to the treasure?\n",
      "A: a trap-door in the roof (model confidence score: 0.001)\n",
      "{'bertscore_f1': 0.6483171582221985,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6107398867607117,\n",
      " 'bertscore_recall': 0.690821647644043,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.5080190867904728}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What hindered Jonathan's access to the treasure?\n",
      "A: Bartholomew Sholto (model confidence score: 0.236)\n",
      "{'bertscore_f1': 0.505920946598053,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4350338578224182,\n",
      " 'bertscore_recall': 0.6044065952301025,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What hindered Jonathan's access to the treasure?\n",
      "A: Bartholomew Sholto was still in the room, (model confidence score: 0.399)\n",
      "{'bertscore_f1': 0.5302692651748657,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.47176918387413025,\n",
      " 'bertscore_recall': 0.6053311824798584,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.27988683572280865}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What hindered Jonathan's access to the treasure?\n",
      "A: wooden leg (model confidence score: 0.847)\n",
      "{'bertscore_f1': 0.9999999403953552,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9999999403953552,\n",
      " 'bertscore_recall': 0.9999999403953552,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What hindered Jonathan's access to the treasure?\n",
      "A: Bartholomew Sholto was still in the room, to his cost (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.4980398714542389,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4234890341758728,\n",
      " 'bertscore_recall': 0.604446291923523,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.230657677963774}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who climbed through the roof for Jonathan Small?\n",
      "Expected Answer: Tonga\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who climbed through the roof for Jonathan Small?\n",
      "A: Bartholomew Sholto (model confidence score: 0.909)\n",
      "{'bertscore_f1': 0.4977540969848633,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4887983798980713,\n",
      " 'bertscore_recall': 0.5070440769195557,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who climbed through the roof for Jonathan Small?\n",
      "A: Bartholomew Sholto (model confidence score: 0.636)\n",
      "{'bertscore_f1': 0.4977540969848633,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4887983798980713,\n",
      " 'bertscore_recall': 0.5070440769195557,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who climbed through the roof for Jonathan Small?\n",
      "A: Tonga (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.9999999403953552,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9999999403953552,\n",
      " 'bertscore_recall': 0.9999999403953552,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who climbed through the roof for Jonathan Small?\n",
      "A: Tonga (model confidence score: 0.018)\n",
      "{'bertscore_f1': 0.9999999403953552,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9999999403953552,\n",
      " 'bertscore_recall': 0.9999999403953552,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who climbed through the roof for Jonathan Small?\n",
      "A: Tonga. (model confidence score: 0.991)\n",
      "{'bertscore_f1': 0.888738751411438,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8556706309318542,\n",
      " 'bertscore_recall': 0.9244654774665833,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who climbed through the roof for Jonathan Small?\n",
      "A: Tonga. (model confidence score: 0.762)\n",
      "{'bertscore_f1': 0.888738751411438,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8556706309318542,\n",
      " 'bertscore_recall': 0.9244654774665833,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who climbed through the roof for Jonathan Small?\n",
      "A: Tonga (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.9999999403953552,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9999999403953552,\n",
      " 'bertscore_recall': 0.9999999403953552,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who was still in the room when Tonga entered?\n",
      "Expected Answer: Bartholomew Sholto\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who was still in the room when Tonga entered?\n",
      "A: Bartholomew Sholto (model confidence score: 0.996)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who was still in the room when Tonga entered?\n",
      "A: Bartholomew Sholto (model confidence score: 0.985)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who was still in the room when Tonga entered?\n",
      "A: Bartholomew Sholto (model confidence score: 0.233)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who was still in the room when Tonga entered?\n",
      "A: Bartholomew Sholto (model confidence score: 0.912)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who was still in the room when Tonga entered?\n",
      "A: Bartholomew Sholto (model confidence score: 0.92)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who was still in the room when Tonga entered?\n",
      "A: Bartholomew Sholto (model confidence score: 0.773)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who was still in the room when Tonga entered?\n",
      "A: Bartholomew Sholto (model confidence score: 0.001)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What did Tonga do to Bartholomew Sholto?\n",
      "Expected Answer: Killed him\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What did Tonga do to Bartholomew Sholto?\n",
      "A: he had done something very clever in killing him (model confidence score: 0.289)\n",
      "{'bertscore_f1': 0.63051837682724,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5326739549636841,\n",
      " 'bertscore_recall': 0.7723962664604187,\n",
      " 'rouge1': 0.1818181818181818,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.1818181818181818,\n",
      " 'rougeLsum': 0.1818181818181818,\n",
      " 'spacy_sim': 0.617322115778448}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What did Tonga do to Bartholomew Sholto?\n",
      "A: Tonga thought he had done something very clever in killing him (model confidence score: 0.024)\n",
      "{'bertscore_f1': 0.5425892472267151,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.43305665254592896,\n",
      " 'bertscore_recall': 0.726288914680481,\n",
      " 'rouge1': 0.15384615384615385,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.15384615384615385,\n",
      " 'rougeLsum': 0.15384615384615385,\n",
      " 'spacy_sim': 0.5605272196751234}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What did Tonga do to Bartholomew Sholto?\n",
      "A: killing him (model confidence score: 0.404)\n",
      "{'bertscore_f1': 0.8936544060707092,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8936544060707092,\n",
      " 'bertscore_recall': 0.8936544060707092,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7830225260720117}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What did Tonga do to Bartholomew Sholto?\n",
      "A: killing him (model confidence score: 0.087)\n",
      "{'bertscore_f1': 0.8936544060707092,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8936544060707092,\n",
      " 'bertscore_recall': 0.8936544060707092,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7830225260720117}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What did Tonga do to Bartholomew Sholto?\n",
      "A: killing him, (model confidence score: 0.946)\n",
      "{'bertscore_f1': 0.8293399810791016,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.777628481388092,\n",
      " 'bertscore_recall': 0.8884190320968628,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7830225260720117}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What did Tonga do to Bartholomew Sholto?\n",
      "A: killing him, (model confidence score: 0.585)\n",
      "{'bertscore_f1': 0.8293399810791016,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.777628481388092,\n",
      " 'bertscore_recall': 0.8884190320968628,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7830225260720117}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What did Tonga do to Bartholomew Sholto?\n",
      "A: Tonga thought he had done something very clever in killing him (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.5425892472267151,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.43305665254592896,\n",
      " 'bertscore_recall': 0.726288914680481,\n",
      " 'rouge1': 0.15384615384615385,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.15384615384615385,\n",
      " 'rougeLsum': 0.15384615384615385,\n",
      " 'spacy_sim': 0.5605272196751234}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What symbol did the narrator leave on the table?\n",
      "Expected Answer: Sign of the four\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What symbol did the narrator leave on the table?\n",
      "A: the sign of the four (model confidence score: 0.494)\n",
      "{'bertscore_f1': 0.7846453785896301,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.784517228603363,\n",
      " 'bertscore_recall': 0.7847735285758972,\n",
      " 'rouge1': 0.888888888888889,\n",
      " 'rouge2': 0.8571428571428571,\n",
      " 'rougeL': 0.888888888888889,\n",
      " 'rougeLsum': 0.888888888888889,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What symbol did the narrator leave on the table?\n",
      "A: four (model confidence score: 0.362)\n",
      "{'bertscore_f1': 0.4784289002418518,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6029884815216064,\n",
      " 'bertscore_recall': 0.39651966094970703,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What symbol did the narrator leave on the table?\n",
      "A: four (model confidence score: 0.074)\n",
      "{'bertscore_f1': 0.4784289002418518,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6029884815216064,\n",
      " 'bertscore_recall': 0.39651966094970703,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What symbol did the narrator leave on the table?\n",
      "A: the sign of the four (model confidence score: 0.684)\n",
      "{'bertscore_f1': 0.7846453785896301,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.784517228603363,\n",
      " 'bertscore_recall': 0.7847735285758972,\n",
      " 'rouge1': 0.888888888888889,\n",
      " 'rouge2': 0.8571428571428571,\n",
      " 'rougeL': 0.888888888888889,\n",
      " 'rougeLsum': 0.888888888888889,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What symbol did the narrator leave on the table?\n",
      "A: sign of the four (model confidence score: 0.968)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What symbol did the narrator leave on the table?\n",
      "A: the sign of the four (model confidence score: 0.457)\n",
      "{'bertscore_f1': 0.7846453785896301,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.784517228603363,\n",
      " 'bertscore_recall': 0.7847735285758972,\n",
      " 'rouge1': 0.888888888888889,\n",
      " 'rouge2': 0.8571428571428571,\n",
      " 'rougeL': 0.888888888888889,\n",
      " 'rougeLsum': 0.888888888888889,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What symbol did the narrator leave on the table?\n",
      "A: sign of the four (model confidence score: 0.356)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "Found: ['evidence.0.md', 'evidence.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "\"Just sit in the corner there, that your footprints may not complicate matters. Now to work! In the first place, how did these folk come, and how did they go? The door has not been opened since last night. How of the window?\" He carried the lamp across to it, muttering his observations aloud the while, but addressing them to himself rather than to me. \"Window is snibbed on the inner side. Framework is solid. No hinges at the side. Let us open it. No water-pipe near. Roof quite out of reach. Yet a man has mounted by the window. It rained a little last night. Here is the print of a foot in mould upon the sill. And here is a circular muddy mark, and here again upon the floor, and here again by the table. See here, Watson! This is really a very pretty demonstration.\" I looked at the round, well-defined muddy discs. \"This is not a footmark,\" said I. \"It is something much more valuable to us. It is the impression of a wooden stump. You see here on the sill is the boot-mark, a heavy boot with the broad metal heel, and beside it is the mark of the timber-toe.\" \"It is the wooden-legged man.\" \"Quite so. But there has been some one else,-a very able and efficient ally. Could you scale that wall, doctor?\" I looked out of the open window. The moon still shone brightly on that angle of the house. We were a good sixty feet from the ground, and, look where I would, I could see no foothold, nor as much as a crevice in the brick-work. \"It is absolutely impossible,\" I answered. \"Without aid it is so. But suppose you had a friend up here who lowered you this good stout\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What kind of mark was found beside the boot-mark?\n",
      "Expected Answer: Circular muddy mark\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What kind of mark was found beside the boot-mark?\n",
      "A: timber-toe (model confidence score: 0.534)\n",
      "{'bertscore_f1': 0.6372380256652832,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6372380256652832,\n",
      " 'bertscore_recall': 0.6372380256652832,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.413825731983079}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What kind of mark was found beside the boot-mark?\n",
      "A: the mark of the timber-toe (model confidence score: 0.476)\n",
      "{'bertscore_f1': 0.6770625114440918,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6209444403648376,\n",
      " 'bertscore_recall': 0.7443317770957947,\n",
      " 'rouge1': 0.2222222222222222,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.2222222222222222,\n",
      " 'rougeLsum': 0.2222222222222222,\n",
      " 'spacy_sim': 0.6920172402523291}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What kind of mark was found beside the boot-mark?\n",
      "A: timber-toe (model confidence score: 0.351)\n",
      "{'bertscore_f1': 0.6372380256652832,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6372380256652832,\n",
      " 'bertscore_recall': 0.6372380256652832,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.413825731983079}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What kind of mark was found beside the boot-mark?\n",
      "A: timber-toe (model confidence score: 0.782)\n",
      "{'bertscore_f1': 0.6372380256652832,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6372380256652832,\n",
      " 'bertscore_recall': 0.6372380256652832,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.413825731983079}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What kind of mark was found beside the boot-mark?\n",
      "A: timber-toe.\" (model confidence score: 0.998)\n",
      "{'bertscore_f1': 0.6059853434562683,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6058323383331299,\n",
      " 'bertscore_recall': 0.6061384677886963,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.413825731983079}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What kind of mark was found beside the boot-mark?\n",
      "A: the mark of the timber-toe.\" (model confidence score: 0.62)\n",
      "{'bertscore_f1': 0.6702098250389099,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6229680776596069,\n",
      " 'bertscore_recall': 0.7252045273780823,\n",
      " 'rouge1': 0.2222222222222222,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.2222222222222222,\n",
      " 'rougeLsum': 0.2222222222222222,\n",
      " 'spacy_sim': 0.6920172402523291}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What kind of mark was found beside the boot-mark?\n",
      "A: timber-toe (model confidence score: 0.961)\n",
      "{'bertscore_f1': 0.6372380256652832,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6372380256652832,\n",
      " 'bertscore_recall': 0.6372380256652832,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.413825731983079}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who was suspected due to the mark?\n",
      "Expected Answer: Wooden-legged man\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who was suspected due to the mark?\n",
      "A: timber-toe (model confidence score: 0.174)\n",
      "{'bertscore_f1': 0.6415064930915833,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6609432697296143,\n",
      " 'bertscore_recall': 0.6231802701950073,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.44770549886049177}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who was suspected due to the mark?\n",
      "A: the timber-toe (model confidence score: 0.475)\n",
      "{'bertscore_f1': 0.5894513130187988,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6074831485748291,\n",
      " 'bertscore_recall': 0.5724591016769409,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.44770549886049177}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who was suspected due to the mark?\n",
      "A: the wooden-legged man (model confidence score: 0.003)\n",
      "{'bertscore_f1': 0.8060775399208069,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8125274777412415,\n",
      " 'bertscore_recall': 0.7997292280197144,\n",
      " 'rouge1': 0.8571428571428571,\n",
      " 'rouge2': 0.8,\n",
      " 'rougeL': 0.8571428571428571,\n",
      " 'rougeLsum': 0.8571428571428571,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who was suspected due to the mark?\n",
      "A: the wooden-legged man (model confidence score: 0.425)\n",
      "{'bertscore_f1': 0.8060775399208069,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8125274777412415,\n",
      " 'bertscore_recall': 0.7997292280197144,\n",
      " 'rouge1': 0.8571428571428571,\n",
      " 'rouge2': 0.8,\n",
      " 'rougeL': 0.8571428571428571,\n",
      " 'rougeLsum': 0.8571428571428571,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who was suspected due to the mark?\n",
      "A: the wooden-legged man.\" (model confidence score: 0.415)\n",
      "{'bertscore_f1': 0.7541866898536682,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7356845140457153,\n",
      " 'bertscore_recall': 0.7736434936523438,\n",
      " 'rouge1': 0.8571428571428571,\n",
      " 'rouge2': 0.8,\n",
      " 'rougeL': 0.8571428571428571,\n",
      " 'rougeLsum': 0.8571428571428571,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who was suspected due to the mark?\n",
      "A: the wooden-legged man.\" (model confidence score: 0.023)\n",
      "{'bertscore_f1': 0.7541866898536682,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7356845140457153,\n",
      " 'bertscore_recall': 0.7736434936523438,\n",
      " 'rouge1': 0.8571428571428571,\n",
      " 'rouge2': 0.8,\n",
      " 'rougeL': 0.8571428571428571,\n",
      " 'rougeLsum': 0.8571428571428571,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who was suspected due to the mark?\n",
      "A: a very able and efficient ally (model confidence score: 0.009)\n",
      "{'bertscore_f1': 0.5284925103187561,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.519001841545105,\n",
      " 'bertscore_recall': 0.5383368134498596,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.17423489937331701}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What evidence suggests that the perpetrator committed the crime?\n",
      "Expected Answer: the mark of the timber-toe\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What evidence suggests that the perpetrator committed the crime?\n",
      "A: the boot-mark (model confidence score: 0.007)\n",
      "{'bertscore_f1': 0.7734454870223999,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8239246010780334,\n",
      " 'bertscore_recall': 0.7287945747375488,\n",
      " 'rouge1': 0.4444444444444444,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4444444444444444,\n",
      " 'rougeLsum': 0.4444444444444444,\n",
      " 'spacy_sim': 0.7181015489563207}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What evidence suggests that the perpetrator committed the crime?\n",
      "A: the mark of the timber-toe (model confidence score: 0.044)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What evidence suggests that the perpetrator committed the crime?\n",
      "A: the mark of the timber-toe (model confidence score: 0.011)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What evidence suggests that the perpetrator committed the crime?\n",
      "A: a man has mounted by the window (model confidence score: 0.066)\n",
      "{'bertscore_f1': 0.5871443748474121,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5897021293640137,\n",
      " 'bertscore_recall': 0.5846086144447327,\n",
      " 'rouge1': 0.15384615384615383,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.15384615384615383,\n",
      " 'rougeLsum': 0.15384615384615383,\n",
      " 'spacy_sim': 0.3902030399185256}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What evidence suggests that the perpetrator committed the crime?\n",
      "A: a man has mounted by the window. (model confidence score: 0.477)\n",
      "{'bertscore_f1': 0.5978378653526306,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6169400215148926,\n",
      " 'bertscore_recall': 0.5798830986022949,\n",
      " 'rouge1': 0.15384615384615383,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.15384615384615383,\n",
      " 'rougeLsum': 0.15384615384615383,\n",
      " 'spacy_sim': 0.3902030399185256}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What evidence suggests that the perpetrator committed the crime?\n",
      "A: the print of a foot in mould upon the sill. (model confidence score: 0.007)\n",
      "{'bertscore_f1': 0.720166802406311,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.731096088886261,\n",
      " 'bertscore_recall': 0.7095595598220825,\n",
      " 'rouge1': 0.37499999999999994,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.37499999999999994,\n",
      " 'rougeLsum': 0.37499999999999994,\n",
      " 'spacy_sim': 0.616725230470533}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What evidence suggests that the perpetrator committed the crime?\n",
      "A: footprints (model confidence score: 0.254)\n",
      "{'bertscore_f1': 0.5625307559967041,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6086306571960449,\n",
      " 'bertscore_recall': 0.5229225754737854,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.4570293184146487}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is suspected to have mounted by the window?\n",
      "Expected Answer: Wooden-legged man\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who is suspected to have mounted by the window?\n",
      "A: a man (model confidence score: 0.793)\n",
      "{'bertscore_f1': 0.6014522314071655,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.640974760055542,\n",
      " 'bertscore_recall': 0.5665205717086792,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.7795917986953637}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who is suspected to have mounted by the window?\n",
      "A: a man (model confidence score: 0.852)\n",
      "{'bertscore_f1': 0.6014522314071655,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.640974760055542,\n",
      " 'bertscore_recall': 0.5665205717086792,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.7795917986953637}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who is suspected to have mounted by the window?\n",
      "A: a man (model confidence score: 0.587)\n",
      "{'bertscore_f1': 0.6014522314071655,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.640974760055542,\n",
      " 'bertscore_recall': 0.5665205717086792,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.7795917986953637}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is suspected to have mounted by the window?\n",
      "A: wooden-legged man (model confidence score: 0.177)\n",
      "{'bertscore_f1': 0.9999999403953552,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9999999403953552,\n",
      " 'bertscore_recall': 0.9999999403953552,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who is suspected to have mounted by the window?\n",
      "A: a man (model confidence score: 0.972)\n",
      "{'bertscore_f1': 0.6014522314071655,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.640974760055542,\n",
      " 'bertscore_recall': 0.5665205717086792,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.7795917986953637}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who is suspected to have mounted by the window?\n",
      "A: a man (model confidence score: 0.611)\n",
      "{'bertscore_f1': 0.6014522314071655,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.640974760055542,\n",
      " 'bertscore_recall': 0.5665205717086792,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.7795917986953637}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who is suspected to have mounted by the window?\n",
      "A: a man (model confidence score: 0.981)\n",
      "{'bertscore_f1': 0.6014522314071655,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.640974760055542,\n",
      " 'bertscore_recall': 0.5665205717086792,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.7795917986953637}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What specific feature of the boot was noticed?\n",
      "Expected Answer: Metal heel\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What specific feature of the boot was noticed?\n",
      "A: broad metal heel (model confidence score: 0.347)\n",
      "{'bertscore_f1': 0.8221580982208252,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8001294136047363,\n",
      " 'bertscore_recall': 0.8454340696334839,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 0.8811241967815432}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What specific feature of the boot was noticed?\n",
      "A: timber-toe (model confidence score: 0.238)\n",
      "{'bertscore_f1': 0.6402126550674438,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6369176506996155,\n",
      " 'bertscore_recall': 0.6435418128967285,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.6406998529510737}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What specific feature of the boot was noticed?\n",
      "A: broad metal heel (model confidence score: 0.25)\n",
      "{'bertscore_f1': 0.8221580982208252,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8001294136047363,\n",
      " 'bertscore_recall': 0.8454340696334839,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 0.8811241967815432}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What specific feature of the boot was noticed?\n",
      "A: broad metal heel (model confidence score: 0.81)\n",
      "{'bertscore_f1': 0.8221580982208252,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8001294136047363,\n",
      " 'bertscore_recall': 0.8454340696334839,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 0.8811241967815432}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What specific feature of the boot was noticed?\n",
      "A: timber-toe.\" (model confidence score: 0.722)\n",
      "{'bertscore_f1': 0.6305679082870483,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6429672241210938,\n",
      " 'bertscore_recall': 0.6186378002166748,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.6406998529510737}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What specific feature of the boot was noticed?\n",
      "A: broad metal heel, (model confidence score: 0.562)\n",
      "{'bertscore_f1': 0.8114517331123352,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7617102861404419,\n",
      " 'bertscore_recall': 0.868143618106842,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 0.8811241967815432}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What specific feature of the boot was noticed?\n",
      "A: mark of the timber-toe (model confidence score: 0.826)\n",
      "{'bertscore_f1': 0.5674380660057068,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5510846376419067,\n",
      " 'bertscore_recall': 0.5847917795181274,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.6253977042514567}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What specific feature of the boot is mentioned?\n",
      "Expected Answer: Broad metal heel\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What specific feature of the boot is mentioned?\n",
      "A: broad metal heel (model confidence score: 0.417)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What specific feature of the boot is mentioned?\n",
      "A: timber-toe (model confidence score: 0.395)\n",
      "{'bertscore_f1': 0.6927912831306458,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6546549797058105,\n",
      " 'bertscore_recall': 0.7356455326080322,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.5830515762995664}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What specific feature of the boot is mentioned?\n",
      "A: broad metal heel (model confidence score: 0.312)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What specific feature of the boot is mentioned?\n",
      "A: broad metal heel (model confidence score: 0.765)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What specific feature of the boot is mentioned?\n",
      "A: timber-toe.\" (model confidence score: 0.791)\n",
      "{'bertscore_f1': 0.6475313901901245,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6220798492431641,\n",
      " 'bertscore_recall': 0.6751542687416077,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.5830515762995664}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What specific feature of the boot is mentioned?\n",
      "A: broad metal heel, (model confidence score: 0.614)\n",
      "{'bertscore_f1': 0.7972192764282227,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7506530284881592,\n",
      " 'bertscore_recall': 0.8499448895454407,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What specific feature of the boot is mentioned?\n",
      "A: metal heel, and beside it is the mark of the timber-toe (model confidence score: 0.926)\n",
      "{'bertscore_f1': 0.6001370549201965,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5030562877655029,\n",
      " 'bertscore_recall': 0.743647575378418,\n",
      " 'rouge1': 0.26666666666666666,\n",
      " 'rouge2': 0.15384615384615385,\n",
      " 'rougeL': 0.26666666666666666,\n",
      " 'rougeLsum': 0.26666666666666666,\n",
      " 'spacy_sim': 0.8015089401111252}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: How did the characters conclude that someone entered through the window?\n",
      "Expected Answer: Footprint on sill\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: How did the characters conclude that someone entered through the window?\n",
      "A: The moon still shone brightly (model confidence score: 0.035)\n",
      "{'bertscore_f1': 0.3538042902946472,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.3134608566761017,\n",
      " 'bertscore_recall': 0.40606632828712463,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.32762917738349057}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: How did the characters conclude that someone entered through the window?\n",
      "A: It is absolutely impossible (model confidence score: 0.378)\n",
      "{'bertscore_f1': 0.3258712589740753,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.29321253299713135,\n",
      " 'bertscore_recall': 0.3667171597480774,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.3061843277445165}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: How did the characters conclude that someone entered through the window?\n",
      "A: there has been some one else,-a very able and efficient ally (model confidence score: 0.025)\n",
      "{'bertscore_f1': 0.3815586268901825,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.35781753063201904,\n",
      " 'bertscore_recall': 0.408674031496048,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.26509290323383156}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: How did the characters conclude that someone entered through the window?\n",
      "A: a man has mounted by the window (model confidence score: 0.166)\n",
      "{'bertscore_f1': 0.4940081536769867,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.49675849080085754,\n",
      " 'bertscore_recall': 0.49128806591033936,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.42442357558288807}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: How did the characters conclude that someone entered through the window?\n",
      "A: \"It is the wooden-legged man.\" (model confidence score: 0.001)\n",
      "{'bertscore_f1': 0.4478320777416229,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.47049689292907715,\n",
      " 'bertscore_recall': 0.42725053429603577,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2964776449767232}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: How did the characters conclude that someone entered through the window?\n",
      "A: a man has mounted by the window. (model confidence score: 0.037)\n",
      "{'bertscore_f1': 0.5050842761993408,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5193278193473816,\n",
      " 'bertscore_recall': 0.49160122871398926,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.42442357558288807}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: How did the characters conclude that someone entered through the window?\n",
      "A: footprints (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.6997354626655579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7791732549667358,\n",
      " 'bertscore_recall': 0.6349966526031494,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.6754758830462316}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What did they observe on the window sill?\n",
      "Expected Answer: Footprint\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What did they observe on the window sill?\n",
      "A: The moon (model confidence score: 0.594)\n",
      "{'bertscore_f1': 0.4665825366973877,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4665825366973877,\n",
      " 'bertscore_recall': 0.4665825366973877,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.15759522803783918}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What did they observe on the window sill?\n",
      "A: The moon (model confidence score: 0.485)\n",
      "{'bertscore_f1': 0.4665825366973877,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4665825366973877,\n",
      " 'bertscore_recall': 0.4665825366973877,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.15759522803783918}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What did they observe on the window sill?\n",
      "A: the boot-mark (model confidence score: 0.026)\n",
      "{'bertscore_f1': 0.6533071398735046,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6580791473388672,\n",
      " 'bertscore_recall': 0.6486038565635681,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.4045941411485095}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What did they observe on the window sill?\n",
      "A: print of a foot in mould (model confidence score: 0.052)\n",
      "{'bertscore_f1': 0.6143780946731567,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5869958400726318,\n",
      " 'bertscore_recall': 0.6444400548934937,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.5564579195422855}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What did they observe on the window sill?\n",
      "A: mark of the timber-toe.\" (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.530057430267334,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5040310621261597,\n",
      " 'bertscore_recall': 0.5589179396629333,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.3800724971390146}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What did they observe on the window sill?\n",
      "A: the print of a foot in mould (model confidence score: 0.384)\n",
      "{'bertscore_f1': 0.6134693026542664,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5936092138290405,\n",
      " 'bertscore_recall': 0.6347042322158813,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.5564579195422855}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What did they observe on the window sill?\n",
      "A: boot-mark (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.6290626525878906,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6506273150444031,\n",
      " 'bertscore_recall': 0.6088815331459045,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.4045941411485095}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: How far from the ground was the open window?\n",
      "Expected Answer: Sixty feet\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: How far from the ground was the open window?\n",
      "A: sixty feet (model confidence score: 0.769)\n",
      "{'bertscore_f1': 1.000000238418579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.000000238418579,\n",
      " 'bertscore_recall': 1.000000238418579,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: How far from the ground was the open window?\n",
      "A: sixty feet (model confidence score: 0.839)\n",
      "{'bertscore_f1': 1.000000238418579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.000000238418579,\n",
      " 'bertscore_recall': 1.000000238418579,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: How far from the ground was the open window?\n",
      "A: sixty feet (model confidence score: 0.441)\n",
      "{'bertscore_f1': 1.000000238418579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.000000238418579,\n",
      " 'bertscore_recall': 1.000000238418579,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: How far from the ground was the open window?\n",
      "A: sixty feet (model confidence score: 0.39)\n",
      "{'bertscore_f1': 1.000000238418579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.000000238418579,\n",
      " 'bertscore_recall': 1.000000238418579,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: How far from the ground was the open window?\n",
      "A: sixty feet (model confidence score: 0.844)\n",
      "{'bertscore_f1': 1.000000238418579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.000000238418579,\n",
      " 'bertscore_recall': 1.000000238418579,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: How far from the ground was the open window?\n",
      "A: sixty feet (model confidence score: 0.87)\n",
      "{'bertscore_f1': 1.000000238418579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.000000238418579,\n",
      " 'bertscore_recall': 1.000000238418579,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: How far from the ground was the open window?\n",
      "A: sixty feet (model confidence score: 1.0)\n",
      "{'bertscore_f1': 1.000000238418579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.000000238418579,\n",
      " 'bertscore_recall': 1.000000238418579,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "Found: ['resolution.0.md', 'resolution.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "A map is drawn for them by an Englishman named Jonathan Small. You remember that we saw the name upon the chart in Captain Morstan's possession. He had signed it in behalf of himself and his associates,-the sign of the four, as he somewhat dramatically called it. Aided by this chart, the officers-or one of them-gets the treasure and brings it to England, leaving, we will suppose, some condition under which he received it unfulfilled. Now, then, why did not Jonathan Small get the treasure himself? The answer is obvious. The chart is dated at a time when Morstan was brought into close association with convicts. Jonathan Small did not get the treasure because he and his associates were themselves convicts and could not get away.\" \"But that is mere speculation,\" said I. \"It is more than that. It is the only hypothesis which covers the facts. Let us see how it fits in with the sequel. Major Sholto remains at peace for some years, happy in the possession of his treasure. Then he receives a letter from India which gives him a great fright. What was that?\" \"A letter to say that the men whom he had wronged had been set free.\" \"Or had escaped. That is much more likely, for he would have known what their term of imprisonment was. It would not have been a surprise to him. What does he do then? He guards himself against a wooden-legged man,-a white man, mark you, for he mistakes a white tradesman for him, and actually fires a pistol at him. Now, only one white man's name is on the chart. The others are Hindoos or Mohammedans. There is no other white man. Therefore we may say with confidence that the wooden-legged man is identical with Jonathan Small. Does\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who drew the map for the treasure?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who drew the map for the treasure?\n",
      "A: Jonathan Small (model confidence score: 0.931)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who drew the map for the treasure?\n",
      "A: Jonathan Small (model confidence score: 0.915)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who drew the map for the treasure?\n",
      "A: Jonathan Small (model confidence score: 0.767)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who drew the map for the treasure?\n",
      "A: Jonathan Small (model confidence score: 0.778)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who drew the map for the treasure?\n",
      "A: Jonathan Small. (model confidence score: 0.923)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who drew the map for the treasure?\n",
      "A: Jonathan Small. (model confidence score: 0.87)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who drew the map for the treasure?\n",
      "A: Jonathan Small (model confidence score: 0.895)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Whose possession was the chart originally in?\n",
      "Expected Answer: Captain Morstan\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Whose possession was the chart originally in?\n",
      "A: Captain Morstan (model confidence score: 0.7)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Whose possession was the chart originally in?\n",
      "A: Captain Morstan (model confidence score: 0.802)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Whose possession was the chart originally in?\n",
      "A: Captain Morstan (model confidence score: 0.5)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Whose possession was the chart originally in?\n",
      "A: Captain Morstan's (model confidence score: 0.758)\n",
      "{'bertscore_f1': 0.824133574962616,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.780864953994751,\n",
      " 'bertscore_recall': 0.8724786043167114,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Whose possession was the chart originally in?\n",
      "A: Captain Morstan's (model confidence score: 0.724)\n",
      "{'bertscore_f1': 0.824133574962616,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.780864953994751,\n",
      " 'bertscore_recall': 0.8724786043167114,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Whose possession was the chart originally in?\n",
      "A: Captain Morstan's (model confidence score: 0.565)\n",
      "{'bertscore_f1': 0.824133574962616,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.780864953994751,\n",
      " 'bertscore_recall': 0.8724786043167114,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Whose possession was the chart originally in?\n",
      "A: Captain Morstan (model confidence score: 0.999)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What is the name of the group associated with Small?\n",
      "Expected Answer: The sign of the four\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What is the name of the group associated with Small?\n",
      "A: Hindoos or Mohammedans (model confidence score: 0.493)\n",
      "{'bertscore_f1': 0.4775752127170563,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4416229724884033,\n",
      " 'bertscore_recall': 0.5198999047279358,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What is the name of the group associated with Small?\n",
      "A: Hindoos or Mohammedans (model confidence score: 0.628)\n",
      "{'bertscore_f1': 0.4775752127170563,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4416229724884033,\n",
      " 'bertscore_recall': 0.5198999047279358,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What is the name of the group associated with Small?\n",
      "A: convicts (model confidence score: 0.019)\n",
      "{'bertscore_f1': 0.46290555596351624,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4617210328578949,\n",
      " 'bertscore_recall': 0.46409618854522705,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.11464342219017191}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What is the name of the group associated with Small?\n",
      "A: he and his associates (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.5136165618896484,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5636311769485474,\n",
      " 'bertscore_recall': 0.47175469994544983,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2424952491604731}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What is the name of the group associated with Small?\n",
      "A: he and his associates were themselves convicts and could not get away.\" (model confidence score: 0.001)\n",
      "{'bertscore_f1': 0.42974185943603516,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.40200164914131165,\n",
      " 'bertscore_recall': 0.4615943133831024,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.17329869399152295}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What is the name of the group associated with Small?\n",
      "A: associates,-the sign of the four, (model confidence score: 0.027)\n",
      "{'bertscore_f1': 0.8302237391471863,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7632640600204468,\n",
      " 'bertscore_recall': 0.9100615978240967,\n",
      " 'rouge1': 0.9090909090909091,\n",
      " 'rouge2': 0.888888888888889,\n",
      " 'rougeL': 0.9090909090909091,\n",
      " 'rougeLsum': 0.9090909090909091,\n",
      " 'spacy_sim': 1.0000000500779673}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What is the name of the group associated with Small?\n",
      "A: convicts (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.46290555596351624,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4617210328578949,\n",
      " 'bertscore_recall': 0.46409618854522705,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.11464342219017191}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What symbol did Jonathan Small use on the chart?\n",
      "Expected Answer: Sign of the four\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What symbol did Jonathan Small use on the chart?\n",
      "A: four (model confidence score: 0.235)\n",
      "{'bertscore_f1': 0.4784289002418518,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6029884815216064,\n",
      " 'bertscore_recall': 0.39651966094970703,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What symbol did Jonathan Small use on the chart?\n",
      "A: the four (model confidence score: 0.365)\n",
      "{'bertscore_f1': 0.5882622599601746,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.660781741142273,\n",
      " 'bertscore_recall': 0.5300862789154053,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.5,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What symbol did Jonathan Small use on the chart?\n",
      "A: the sign of the four (model confidence score: 0.074)\n",
      "{'bertscore_f1': 0.7846453785896301,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.784517228603363,\n",
      " 'bertscore_recall': 0.7847735285758972,\n",
      " 'rouge1': 0.888888888888889,\n",
      " 'rouge2': 0.8571428571428571,\n",
      " 'rougeL': 0.888888888888889,\n",
      " 'rougeLsum': 0.888888888888889,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What symbol did Jonathan Small use on the chart?\n",
      "A: the sign of the four (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.7846453785896301,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.784517228603363,\n",
      " 'bertscore_recall': 0.7847735285758972,\n",
      " 'rouge1': 0.888888888888889,\n",
      " 'rouge2': 0.8571428571428571,\n",
      " 'rougeL': 0.888888888888889,\n",
      " 'rougeLsum': 0.888888888888889,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What symbol did Jonathan Small use on the chart?\n",
      "A: wooden-legged man (model confidence score: 0.031)\n",
      "{'bertscore_f1': 0.42006921768188477,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.449484258890152,\n",
      " 'bertscore_recall': 0.39426764845848083,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.07174329275458166}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What symbol did Jonathan Small use on the chart?\n",
      "A: associates,-the sign of the four, (model confidence score: 0.634)\n",
      "{'bertscore_f1': 0.6848446130752563,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6343172192573547,\n",
      " 'bertscore_recall': 0.7441183924674988,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.7499999999999999,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0000000500779673}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What symbol did Jonathan Small use on the chart?\n",
      "A: wooden-legged man (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.42006921768188477,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.449484258890152,\n",
      " 'bertscore_recall': 0.39426764845848083,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.07174329275458166}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "Expected Answer: He was a convict\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "A: he and his associates were themselves convicts (model confidence score: 0.385)\n",
      "{'bertscore_f1': 0.7108634114265442,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6266785860061646,\n",
      " 'bertscore_recall': 0.8211760520935059,\n",
      " 'rouge1': 0.18181818181818182,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.18181818181818182,\n",
      " 'rougeLsum': 0.18181818181818182,\n",
      " 'spacy_sim': 0.737820439213781}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "A: he and his associates were themselves convicts (model confidence score: 0.192)\n",
      "{'bertscore_f1': 0.7108634114265442,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6266785860061646,\n",
      " 'bertscore_recall': 0.8211760520935059,\n",
      " 'rouge1': 0.18181818181818182,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.18181818181818182,\n",
      " 'rougeLsum': 0.18181818181818182,\n",
      " 'spacy_sim': 0.737820439213781}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "A: he and his associates were themselves convicts (model confidence score: 0.309)\n",
      "{'bertscore_f1': 0.7108634114265442,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6266785860061646,\n",
      " 'bertscore_recall': 0.8211760520935059,\n",
      " 'rouge1': 0.18181818181818182,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.18181818181818182,\n",
      " 'rougeLsum': 0.18181818181818182,\n",
      " 'spacy_sim': 0.737820439213781}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "A: he and his associates were themselves convicts and could not get away (model confidence score: 0.347)\n",
      "{'bertscore_f1': 0.6252064108848572,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5234562158584595,\n",
      " 'bertscore_recall': 0.7760577201843262,\n",
      " 'rouge1': 0.125,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.125,\n",
      " 'rougeLsum': 0.125,\n",
      " 'spacy_sim': 0.5283875959223574}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "A: he and his associates were themselves convicts and could not get away.\" (model confidence score: 0.558)\n",
      "{'bertscore_f1': 0.6539857983589172,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5585144758224487,\n",
      " 'bertscore_recall': 0.7888262867927551,\n",
      " 'rouge1': 0.125,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.125,\n",
      " 'rougeLsum': 0.125,\n",
      " 'spacy_sim': 0.5283875959223574}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "A: he and his associates were themselves convicts and could not get away.\" (model confidence score: 0.312)\n",
      "{'bertscore_f1': 0.6539857983589172,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5585144758224487,\n",
      " 'bertscore_recall': 0.7888262867927551,\n",
      " 'rouge1': 0.125,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.125,\n",
      " 'rougeLsum': 0.125,\n",
      " 'spacy_sim': 0.5283875959223574}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "A: he and his associates were themselves convicts and could not get away (model confidence score: 0.659)\n",
      "{'bertscore_f1': 0.6252064108848572,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5234562158584595,\n",
      " 'bertscore_recall': 0.7760577201843262,\n",
      " 'rouge1': 0.125,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.125,\n",
      " 'rougeLsum': 0.125,\n",
      " 'spacy_sim': 0.5283875959223574}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What caused Major Sholto distress?\n",
      "Expected Answer: A letter from India\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What caused Major Sholto distress?\n",
      "A: a letter (model confidence score: 0.31)\n",
      "{'bertscore_f1': 0.6707197427749634,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.859015941619873,\n",
      " 'bertscore_recall': 0.55013108253479,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.5,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.766604860910085}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What caused Major Sholto distress?\n",
      "A: fires a pistol at him (model confidence score: 0.072)\n",
      "{'bertscore_f1': 0.4355737566947937,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5023678541183472,\n",
      " 'bertscore_recall': 0.38445693254470825,\n",
      " 'rouge1': 0.22222222222222224,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.22222222222222224,\n",
      " 'rougeLsum': 0.22222222222222224,\n",
      " 'spacy_sim': 0.09413129978022741}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What caused Major Sholto distress?\n",
      "A: a letter from India (model confidence score: 0.201)\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What caused Major Sholto distress?\n",
      "A: a letter from India (model confidence score: 0.309)\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What caused Major Sholto distress?\n",
      "A: a letter from India (model confidence score: 0.214)\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What caused Major Sholto distress?\n",
      "A: a letter from India (model confidence score: 0.275)\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What caused Major Sholto distress?\n",
      "A: a letter from India (model confidence score: 0.364)\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What did the letter inform Major Sholto?\n",
      "Expected Answer: Men were freed/escaped\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What did the letter inform Major Sholto?\n",
      "A: a great fright (model confidence score: 0.234)\n",
      "{'bertscore_f1': 0.4817464053630829,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.473430871963501,\n",
      " 'bertscore_recall': 0.49035927653312683,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.3239286405942229}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What did the letter inform Major Sholto?\n",
      "A: fires a pistol at him (model confidence score: 0.022)\n",
      "{'bertscore_f1': 0.47333383560180664,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5044302344322205,\n",
      " 'bertscore_recall': 0.44584882259368896,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.3300982167262101}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What did the letter inform Major Sholto?\n",
      "A: the men whom he had wronged had been set free (model confidence score: 0.146)\n",
      "{'bertscore_f1': 0.6318962574005127,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6082768440246582,\n",
      " 'bertscore_recall': 0.6574240922927856,\n",
      " 'rouge1': 0.14285714285714288,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.14285714285714288,\n",
      " 'rougeLsum': 0.14285714285714288,\n",
      " 'spacy_sim': 0.7202586107978194}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What did the letter inform Major Sholto?\n",
      "A: that the men whom he had wronged had been set free (model confidence score: 0.327)\n",
      "{'bertscore_f1': 0.6127269268035889,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5836127400398254,\n",
      " 'bertscore_recall': 0.644898533821106,\n",
      " 'rouge1': 0.13333333333333333,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.13333333333333333,\n",
      " 'rougeLsum': 0.13333333333333333,\n",
      " 'spacy_sim': 0.7202586107978194}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What did the letter inform Major Sholto?\n",
      "A: the men whom he had wronged had been set free.\" (model confidence score: 0.569)\n",
      "{'bertscore_f1': 0.6443760395050049,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6276983618736267,\n",
      " 'bertscore_recall': 0.6619640588760376,\n",
      " 'rouge1': 0.14285714285714288,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.14285714285714288,\n",
      " 'rougeLsum': 0.14285714285714288,\n",
      " 'spacy_sim': 0.7202586107978194}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What did the letter inform Major Sholto?\n",
      "A: the men whom he had wronged had been set free.\" (model confidence score: 0.31)\n",
      "{'bertscore_f1': 0.6443760395050049,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6276983618736267,\n",
      " 'bertscore_recall': 0.6619640588760376,\n",
      " 'rouge1': 0.14285714285714288,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.14285714285714288,\n",
      " 'rougeLsum': 0.14285714285714288,\n",
      " 'spacy_sim': 0.7202586107978194}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What did the letter inform Major Sholto?\n",
      "A: that the men whom he had wronged had been set free (model confidence score: 0.273)\n",
      "{'bertscore_f1': 0.6127269268035889,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5836127400398254,\n",
      " 'bertscore_recall': 0.644898533821106,\n",
      " 'rouge1': 0.13333333333333333,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.13333333333333333,\n",
      " 'rougeLsum': 0.13333333333333333,\n",
      " 'spacy_sim': 0.7202586107978194}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What action did Major Sholto take against the mistaken man?\n",
      "Expected Answer: Fired a pistol\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: What action did Major Sholto take against the mistaken man?\n",
      "A: fires a pistol at him (model confidence score: 0.308)\n",
      "{'bertscore_f1': 0.762391984462738,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6728178262710571,\n",
      " 'bertscore_recall': 0.8794797658920288,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.3333333333333333,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7630856691898642}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: What action did Major Sholto take against the mistaken man?\n",
      "A: fires a pistol at him (model confidence score: 0.286)\n",
      "{'bertscore_f1': 0.762391984462738,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6728178262710571,\n",
      " 'bertscore_recall': 0.8794797658920288,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.3333333333333333,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7630856691898642}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: What action did Major Sholto take against the mistaken man?\n",
      "A: fires a pistol at him (model confidence score: 0.242)\n",
      "{'bertscore_f1': 0.762391984462738,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6728178262710571,\n",
      " 'bertscore_recall': 0.8794797658920288,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.3333333333333333,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7630856691898642}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What action did Major Sholto take against the mistaken man?\n",
      "A: fires a pistol at him (model confidence score: 0.48)\n",
      "{'bertscore_f1': 0.762391984462738,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6728178262710571,\n",
      " 'bertscore_recall': 0.8794797658920288,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.3333333333333333,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7630856691898642}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: What action did Major Sholto take against the mistaken man?\n",
      "A: fires a pistol (model confidence score: 0.992)\n",
      "{'bertscore_f1': 0.9594839215278625,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9594839215278625,\n",
      " 'bertscore_recall': 0.9594839215278625,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.5,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.7630856691898642}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: What action did Major Sholto take against the mistaken man?\n",
      "A: fires a pistol at him. (model confidence score: 0.432)\n",
      "{'bertscore_f1': 0.7630211710929871,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6794803142547607,\n",
      " 'bertscore_recall': 0.8699840307235718,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.3333333333333333,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7630856691898642}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: What action did Major Sholto take against the mistaken man?\n",
      "A: actually fires a pistol at him (model confidence score: 0.266)\n",
      "{'bertscore_f1': 0.7406244277954102,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6480984687805176,\n",
      " 'bertscore_recall': 0.8639692068099976,\n",
      " 'rouge1': 0.4444444444444444,\n",
      " 'rouge2': 0.28571428571428575,\n",
      " 'rougeL': 0.4444444444444444,\n",
      " 'rougeLsum': 0.4444444444444444,\n",
      " 'spacy_sim': 0.6863050619889615}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the only white man on the chart?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-cased-distilled-squad\n",
      "Q: Who is the only white man on the chart?\n",
      "A: Hindoos or Mohammedans (model confidence score: 0.374)\n",
      "{'bertscore_f1': 0.44985005259513855,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.443495512008667,\n",
      " 'bertscore_recall': 0.45638930797576904,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: distilbert-base-uncased-distilled-squad\n",
      "Q: Who is the only white man on the chart?\n",
      "A: Major Sholto (model confidence score: 0.737)\n",
      "{'bertscore_f1': 0.4802674949169159,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5099644064903259,\n",
      " 'bertscore_recall': 0.45383894443511963,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.40285111986286953}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-base-squad2\n",
      "Q: Who is the only white man on the chart?\n",
      "A: Hindoos or Mohammedans (model confidence score: 0.021)\n",
      "{'bertscore_f1': 0.44985005259513855,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.443495512008667,\n",
      " 'bertscore_recall': 0.45638930797576904,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the only white man on the chart?\n",
      "A: Jonathan Small (model confidence score: 0.019)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-base-squad2\n",
      "Q: Who is the only white man on the chart?\n",
      "A: Jonathan Small. (model confidence score: 0.248)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/deberta-v3-large-squad2\n",
      "Q: Who is the only white man on the chart?\n",
      "A: Jonathan Small. (model confidence score: 0.431)\n",
      "{'bertscore_f1': 0.902590274810791,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8710358142852783,\n",
      " 'bertscore_recall': 0.9365168809890747,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/electra-base-squad2\n",
      "Q: Who is the only white man on the chart?\n",
      "A: Jonathan Small (model confidence score: 0.168)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"res_qa.csv\"\n",
    "csv_header = [\n",
    "    \"ctx_name\",\n",
    "    \"ctx_fname\",\n",
    "    \"q_idx\",\n",
    "    \"q_text\",\n",
    "    \"q_answer_true\",\n",
    "    \"qa_model\",\n",
    "    \"qa_answer_pred\",\n",
    "]\n",
    "csv_rows = []\n",
    "\n",
    "for ctx_name in [\"protagonist\", \"antagonist\", \"crime\", \"evidence\", \"resolution\"]:\n",
    "    for ctx_idx, (ctx_fname, ctx_text) in enumerate(utils.read_context(ctx_name)):\n",
    "        ctx_fname = os.path.basename(ctx_fname)\n",
    "        print(\"#\" * 80)\n",
    "        print(\"#\" * 80)\n",
    "        print(ctx_text)\n",
    "\n",
    "        for q_idx, (q_text, q_answer_true) in enumerate(utils.read_qa(ctx_name)):\n",
    "            print(\"=\" * 80)\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"Current Question: {q_text}\")\n",
    "            print(f\"Expected Answer: {q_answer_true}\")\n",
    "\n",
    "            q_answers_preds, q_answers_scores = run_qa_models(\n",
    "                q_text,\n",
    "                ctx_text,\n",
    "                models,\n",
    "                q_answer_true,\n",
    "            )\n",
    "\n",
    "            for qa_model, qa_answer_pred, qa_answer_score in zip(\n",
    "                models, q_answers_preds, q_answers_scores\n",
    "            ):\n",
    "                row = [\n",
    "                    ctx_name,\n",
    "                    ctx_fname,\n",
    "                    q_idx,\n",
    "                    q_text,\n",
    "                    q_answer_true,\n",
    "                    qa_model,\n",
    "                    qa_answer_pred,\n",
    "                ]\n",
    "\n",
    "                for metric, score in qa_answer_score.items():\n",
    "                    if metric not in csv_header:\n",
    "                        csv_header.append(metric)\n",
    "                    row.append(score)\n",
    "\n",
    "                csv_rows.append(row)\n",
    "\n",
    "\n",
    "with open(csv_file, \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(csv_header)\n",
    "    writer.writerows(csv_rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
