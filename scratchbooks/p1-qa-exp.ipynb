{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Question Answering\n",
    "\n",
    "For the first part, use the Hugging Face question-answering pipeline and feed it with the five 300-word long sections from the book of your choice that you analyzed in Project 1.\n",
    "\n",
    "These sections should be selected so they are: introducing the protagonist(s), the antagonist, the crime and crime scene, any significant evidence, and the resolution of the crime/a narrative that presents the case against the perpetrator.\n",
    "\n",
    "For a prompt, Implement a simple prompt interface that takes in your question, runs it against the model, and returns the answer. You don't need to do anything special about this, just a simple console I/O interface without any complicated error handling. It is up to you how you want to upload the context to the model (pre-loaded into your program, on-demand, etc.).\n",
    "\n",
    "The questions you should ask are about the identity and characteristics of the protagonist, antagonist/perpetrator, the nature and the setting of the crime or crime scene, the evidence, and the case against the perpetrator.\n",
    "\n",
    "Document the questions, ask the questions, and document the specificity and accuracy of the results.\n",
    "\n",
    "Part 1.2 - use two different HF QA models: use the default question-answering pipeline, then use other models of choice and discuss the differences in the result.\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "https://huggingface.co/docs/transformers/v4.35.0/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -r ../requirements.txt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from src import utils\n",
    "from src.question_answering import run, run_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Experiments & Results\n",
    "\n",
    "For the first part, use the Hugging Face question-answering pipeline and feed it with the five 300-word long sections from the book of your choice that you analyzed in Project 1.\n",
    "\n",
    "These sections should be selected so they are: **introducing the protagonist(s), the antagonist, the crime and crime scene, any significant evidence, and the resolution of the crime/a narrative that presents the case against the perpetrator.**\n",
    "\n",
    "The questions you should ask are about the identity and characteristics of the protagonist, antagonist/perpetrator, the nature and the setting of the crime or crime scene, the evidence, and the case against the perpetrator.\n",
    "\n",
    "Document the questions, ask the questions, and document the specificity and accuracy of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try out a good selection of models and keep some interesting ones\n",
    "models = [\n",
    "    \"distilbert-base-uncased-distilled-squad\",\n",
    "    \"deepset/roberta-base-squad2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: ['protagonist.0.md', 'protagonist.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "Sherlock Holmes took his bottle from the corner of the mantel-piece and his hypodermic syringe from its neat morocco case. With his long, white, nervous fingers he adjusted the delicate needle, and rolled back his left shirt-cuff. For some little time his eyes rested thoughtfully upon the sinewy forearm and wrist all dotted and scarred with innumerable puncture-marks. Finally he thrust the sharp point home, pressed down the tiny piston, and sank back into the velvet-lined arm-chair with a long sigh of satisfaction. Three times a day for many months I had witnessed this performance, but custom had not reconciled my mind to it. On the contrary, from day to day I had become more irritable at the sight, and my conscience swelled nightly within me at the thought that I had lacked the courage to protest. Again and again I had registered a vow that I should deliver my soul upon the subject, but there was that in the cool, nonchalant air of my companion which made him the last man with whom one would care to take anything approaching to a liberty. His great powers, his masterly manner, and the experience which I had had of his many extraordinary qualities, all made me diffident and backward in crossing him. Yet upon that afternoon, whether it was the Beaune which I had taken with my lunch, or the additional exasperation produced by the extreme deliberation of his manner, I suddenly felt that I could hold out no longer. \"Which is it to-day?\" I asked,-\"morphine or cocaine?\" He raised his eyes languidly from the old black-letter volume which he had opened. \"It is cocaine,\" he said,-\"a seven-per-cent. solution. Would you care to try it?\" \"No, indeed,\" I answered, brusquely. \"My constitution has not got over the Afghan campaign yet. I\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the main character that the story revolves around?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: the Beaune (model confidence score: 0.588)\n",
      "EVAL SCORE: -0.0026\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: cocaine (model confidence score: 0.153)\n",
      "EVAL SCORE: 0.1067\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the detective in the story?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.866)\n",
      "EVAL SCORE: 1.0\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.478)\n",
      "EVAL SCORE: 1.0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the main protagonist in the story?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.782)\n",
      "EVAL SCORE: 1.0\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: cocaine (model confidence score: 0.101)\n",
      "EVAL SCORE: 0.1067\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What are the defining characteristics or traits of the central character?\n",
      "Expected Answer: [EXPECTED ANSWER HERE]\n",
      "--------------------------------------------------------------------------------\n",
      "Q: What are the defining characteristics or traits of the central character?\n",
      "A: extraordinary qualities (model confidence score: 0.644)\n",
      "EVAL SCORE: 0.1989\n",
      "--------------------------------------------------------------------------------\n",
      "Q: What are the defining characteristics or traits of the central character?\n",
      "A: morphine or cocaine (model confidence score: 0.146)\n",
      "EVAL SCORE: 0.0729\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What are the characteristics of the main protagonist?\n",
      "Expected Answer: [EXPECTED ANSWER HERE]\n",
      "--------------------------------------------------------------------------------\n",
      "Q: What are the characteristics of the main protagonist?\n",
      "A: extraordinary qualities (model confidence score: 0.492)\n",
      "EVAL SCORE: 0.1989\n",
      "--------------------------------------------------------------------------------\n",
      "Q: What are the characteristics of the main protagonist?\n",
      "A: morphine or cocaine (model confidence score: 0.089)\n",
      "EVAL SCORE: 0.0729\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/acozma/Library/Mobile Documents/com~apple~CloudDocs/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/scratchbooks/p1-qa-exp.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/acozma/Library/Mobile%20Documents/com~apple~CloudDocs/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/scratchbooks/p1-qa-exp.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         scores_by_answer[m][true_answer]\u001b[39m.\u001b[39mappend(s)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/acozma/Library/Mobile%20Documents/com~apple~CloudDocs/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/scratchbooks/p1-qa-exp.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         scores_by_question[m][j]\u001b[39m.\u001b[39mappend(s)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/acozma/Library/Mobile%20Documents/com~apple~CloudDocs/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/scratchbooks/p1-qa-exp.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m utils\u001b[39m.\u001b[39;49mcreate_plots(ctx_name, scores_by_model, scores_by_answer, scores_by_question)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/acozma/Library/Mobile%20Documents/com~apple~CloudDocs/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/scratchbooks/p1-qa-exp.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/scratchbooks/src/utils.py:74\u001b[0m, in \u001b[0;36mcreate_plots\u001b[0;34m(ctx_name, scores_by_model, scores_by_answer, scores_by_question_idx)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_plots\u001b[39m(\n\u001b[1;32m     69\u001b[0m     ctx_name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     70\u001b[0m     scores_by_model: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m],\n\u001b[1;32m     71\u001b[0m     scores_by_answer: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m]],\n\u001b[1;32m     72\u001b[0m     scores_by_question_idx: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m]],\n\u001b[1;32m     73\u001b[0m ):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m     76\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m80\u001b[39m)\n\u001b[1;32m     77\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPlotting\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "ctx_name = \"protagonist\"\n",
    "\n",
    "for i, (fname, ctx) in enumerate(utils.read_context(ctx_name)):\n",
    "    print(\"#\" * 80)\n",
    "    print(\"#\" * 80)\n",
    "    print(ctx)\n",
    "\n",
    "    scores_by_question = {m: defaultdict(list) for m in models}\n",
    "    scores_by_answer = {m: defaultdict(list) for m in models}\n",
    "    scores_by_model = defaultdict(list)\n",
    "\n",
    "    for j, (question, true_answer) in enumerate(utils.read_qa(ctx_name)):\n",
    "        print(\"=\" * 80)\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Current Question: {question}\")\n",
    "        print(f\"Expected Answer: {true_answer}\")\n",
    "\n",
    "        # for k in range(5):\n",
    "        _, scores = run_models(\n",
    "            question,\n",
    "            ctx,\n",
    "            models,\n",
    "            expected_answer=true_answer,\n",
    "        )\n",
    "\n",
    "        for m, s in zip(models, scores):\n",
    "            scores_by_model[m].append(s)\n",
    "            scores_by_answer[m][true_answer].append(s)\n",
    "            scores_by_question[m][j].append(s)\n",
    "\n",
    "    utils.create_plots(ctx_name, scores_by_model, scores_by_answer, scores_by_question)\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
