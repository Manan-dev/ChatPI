{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Translation\n",
    "\n",
    "You will modify Part 1 to generate the translations of your answers from Part 1 into a particular language (see below) and then back to English.\n",
    "\n",
    "So, your prompt should look like:\n",
    "\n",
    "> Your question.  \n",
    "> Answer in English.  \n",
    "> Answer in the assigned Language.  \n",
    "> Answer in English, translated from the above language.\n",
    "\n",
    "The language you will use for your project is:\n",
    "\n",
    "Team 1, 4, 7, 10, 13 - Spanish\n",
    "\n",
    "Team 2,5,8,11 - German\n",
    "\n",
    "Team 3,6,9,12 - French\n",
    "\n",
    "Observe the effects of the cyclical translation (e.g., English->French->English) and critique the results in your slides and the report.\n",
    "\n",
    "Part 2.2 -- use two different HF translation models: use the default translation pipeline, then use other models of choice and discuss the differences in the result.\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "https://huggingface.co/docs/transformers/v4.35.0/en/main_classes/pipelines#transformers.TranslationPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg@ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl#sha256=ab70aeb6172cde82508f7739f35ebc9918a3d07debeed637403c8f794ba3d3dc (from -r ../requirements.txt (line 28))\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/587.7 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:36\u001b[0m^C\n",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/587.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:32\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ../requirements.txt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 16:04:58.145168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import read_context, read_questions\n",
    "from src.translation import run, run_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Experiments & Results\n",
    "\n",
    "You will modify Part 1 to generate the translations of your answers from Part 1 into a particular language (see below) and then back to English.\n",
    "\n",
    "Observe the effects of the cyclical translation (e.g., English->French->English) and critique the results in your slides and the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try out a good selection of models and keep some interesting ones\n",
    "models = [\n",
    "    \"t5-base\",\n",
    "    \"t5-large\",\n",
    "    \"Helsinki-NLP/opus-mt-en-fr\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "model: t5-base\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acozma/.local/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
      "his hypodermic syringe from its neat morocco case. With his long,\n",
      "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
      "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
      "upon the sinewy forearm and wrist all dotted and scarred with\n",
      "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
      "pressed down the tiny piston, and sank back into the velvet-lined\n",
      "arm-chair with a long sigh of satisfaction.\n",
      "> Sherlock Holmes a pris sa bouteille du coin du manteau et sa seringue hypodermique de son étui morocco. Avec ses longs doigts blancs et nerveux, il ajusta la délicate aiguille et roulait à l'envers de sa manche gauche. Pendant un peu de temps, ses yeux reposèrent soigneusement sur l'avant-bras\n",
      "====================================================================================================\n",
      "model: t5-large\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acozma/.local/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
      "his hypodermic syringe from its neat morocco case. With his long,\n",
      "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
      "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
      "upon the sinewy forearm and wrist all dotted and scarred with\n",
      "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
      "pressed down the tiny piston, and sank back into the velvet-lined\n",
      "arm-chair with a long sigh of satisfaction.\n",
      "> Sherlock Holmes prenait sa bouteille de l'angle du manteau et sa seringue hypodermique de son étui morocain soigné. Avec ses longs doigts blancs et nerveux, il ajustait l'aiguille délicate et roulait son manteau gauche. Pendant un peu de temps, ses yeux restaient soigneusement sur l'avant-bra\n",
      "====================================================================================================\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "> Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
      "his hypodermic syringe from its neat morocco case. With his long,\n",
      "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
      "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
      "upon the sinewy forearm and wrist all dotted and scarred with\n",
      "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
      "pressed down the tiny piston, and sank back into the velvet-lined\n",
      "arm-chair with a long sigh of satisfaction.\n",
      "> Sherlock Holmes a pris sa bouteille du coin de la cheminée et sa seringue hypodermique de son boîtier morocco soigné. Avec ses doigts longs, blancs et nerveux, il a ajusté l'aiguille délicate, et a roulé sa chemise-cuisse gauche. Pendant un peu de temps, ses yeux reposaient délicatement sur l'avant-bras et le poignet sinueux tous parsemés et marqués d'innombrables marques de ponction. Enfin, il a poussé le point aigu à la maison, a pressé le petit piston, et a coulé dans la chaise de bras doublée de velours avec un long soupir de satisfaction.\n"
     ]
    }
   ],
   "source": [
    "## TODO: add experiments and results\n",
    "\n",
    "test_txt = \"\"\"\n",
    "Sherlock Holmes took his bottle from the corner of the mantel-piece and\n",
    "his hypodermic syringe from its neat morocco case. With his long,\n",
    "white, nervous fingers he adjusted the delicate needle, and rolled back\n",
    "his left shirt-cuff. For some little time his eyes rested thoughtfully\n",
    "upon the sinewy forearm and wrist all dotted and scarred with\n",
    "innumerable puncture-marks. Finally he thrust the sharp point home,\n",
    "pressed down the tiny piston, and sank back into the velvet-lined\n",
    "arm-chair with a long sigh of satisfaction.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "run_models(test_txt, models=models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
