{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Translation\n",
    "\n",
    "You will modify Part 1 to generate the translations of your answers from Part 1 into a particular language (see below) and then back to English.\n",
    "\n",
    "So, your prompt should look like:\n",
    "\n",
    "> Your question.  \n",
    "> Answer in English.  \n",
    "> Answer in the assigned Language.  \n",
    "> Answer in English, translated from the above language.\n",
    "\n",
    "The language you will use for your project is:\n",
    "\n",
    "Team 1, 4, 7, 10, 13 - Spanish\n",
    "\n",
    "Team 2,5,8,11 - German\n",
    "\n",
    "Team 3,6,9,12 - French\n",
    "\n",
    "Observe the effects of the cyclical translation (e.g., English->French->English) and critique the results in your slides and the report.\n",
    "\n",
    "Part 2.2 -- use two different HF translation models: use the default translation pipeline, then use other models of choice and discuss the differences in the result.\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "https://huggingface.co/docs/transformers/v4.35.0/en/main_classes/pipelines#transformers.TranslationPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: matplotlib==3.8.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (3.8.2)\n",
      "Requirement already satisfied: spacy==3.7.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (3.7.2)\n",
      "Requirement already satisfied: torch==2.1.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (4.66.1)\n",
      "Requirement already satisfied: transformers==4.35.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (4.35.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.99 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (0.1.99)\n",
      "Requirement already satisfied: sacremoses==0.1.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (0.1.1)\n",
      "Requirement already satisfied: termcolor==2.3.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: evaluate==0.4.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (0.4.1)\n",
      "Requirement already satisfied: pillow>=8 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (10.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (1.26.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from matplotlib==3.8.2->-r ../requirements.txt (line 1)) (4.45.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (1.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.5.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.4.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.0.10)\n",
      "Requirement already satisfied: setuptools in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (59.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (0.3.4)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (8.2.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (6.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from spacy==3.7.2->-r ../requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (10.3.2.106)\n",
      "Requirement already satisfied: triton==2.1.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: fsspec in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (2023.10.0)\n",
      "Requirement already satisfied: networkx in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: sympy in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.0.106)\n",
      "Requirement already satisfied: filelock in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from torch==2.1.1->-r ../requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (0.17.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from transformers==4.35.0->-r ../requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: joblib in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from sacremoses==0.1.1->-r ../requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: click in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from sacremoses==0.1.1->-r ../requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: responses<0.19 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (3.4.1)\n",
      "Requirement already satisfied: pandas in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (2.1.3)\n",
      "Requirement already satisfied: multiprocess in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (0.70.15)\n",
      "Requirement already satisfied: dill in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (0.3.7)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from evaluate==0.4.1->-r ../requirements.txt (line 10)) (2.14.7)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1->-r ../requirements.txt (line 3)) (12.3.101)\n",
      "Requirement already satisfied: aiohttp in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (3.9.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (0.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (14.0.1)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->-r ../requirements.txt (line 2)) (2.14.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2->-r ../requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.8.2->-r ../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->-r ../requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2->-r ../requirements.txt (line 2)) (0.7.11)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.2->-r ../requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from jinja2->spacy==3.7.2->-r ../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from pandas->evaluate==0.4.1->-r ../requirements.txt (line 10)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from pandas->evaluate==0.4.1->-r ../requirements.txt (line 10)) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from sympy->torch==2.1.1->-r ../requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1->-r ../requirements.txt (line 10)) (6.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ../requirements.txt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from src import utils\n",
    "from src.question_answering import run_qa_models\n",
    "from src.translation import run_tr_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Experiments & Results\n",
    "\n",
    "You will modify Part 1 to generate the translations of your answers from Part 1 into a particular language (see below) and then back to English.\n",
    "\n",
    "Observe the effects of the cyclical translation (e.g., English->French->English) and critique the results in your slides and the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only use the best question answering model\n",
    "models_qa = [\n",
    "    # DistilBERT\n",
    "    # \"distilbert-base-cased-distilled-squad\",\n",
    "    # \"distilbert-base-uncased-distilled-squad\",\n",
    "    # RoBERTa\n",
    "    # \"deepset/roberta-base-squad2\",\n",
    "    \"deepset/roberta-large-squad2\",\n",
    "    # Deberta\n",
    "    # \"deepset/deberta-v3-base-squad2\",\n",
    "    # \"deepset/deberta-v3-large-squad2\",\n",
    "    # Electra\n",
    "    # \"deepset/electra-base-squad2\",\n",
    "]\n",
    "\n",
    "# Models for translating the answers given by the question answering models\n",
    "models_tr = [\n",
    "    # the opus models are trained specifically for en-fr and fr-en\n",
    "    (\"Helsinki-NLP/opus-mt-en-fr\", \"Helsinki-NLP/opus-mt-fr-en\"),\n",
    "    # the facebook m2m100 models are supposed to be multilingual\n",
    "    (\"facebook/m2m100_418M\", \"facebook/m2m100_418M\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: ['protagonist.0.md', 'protagonist.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "Sherlock Holmes took his bottle from the corner of the mantel-piece and his hypodermic syringe from its neat morocco case. With his long, white, nervous fingers he adjusted the delicate needle, and rolled back his left shirt-cuff. For some little time his eyes rested thoughtfully upon the sinewy forearm and wrist all dotted and scarred with innumerable puncture-marks. Finally he thrust the sharp point home, pressed down the tiny piston, and sank back into the velvet-lined arm-chair with a long sigh of satisfaction. Three times a day for many months I had witnessed this performance, but custom had not reconciled my mind to it. On the contrary, from day to day I had become more irritable at the sight, and my conscience swelled nightly within me at the thought that I had lacked the courage to protest. Again and again I had registered a vow that I should deliver my soul upon the subject, but there was that in the cool, nonchalant air of my companion which made him the last man with whom one would care to take anything approaching to a liberty. His great powers, his masterly manner, and the experience which I had had of his many extraordinary qualities, all made me diffident and backward in crossing him. Yet upon that afternoon, whether it was the Beaune which I had taken with my lunch, or the additional exasperation produced by the extreme deliberation of his manner, I suddenly felt that I could hold out no longer. \"Which is it to-day?\" I asked,-\"morphine or cocaine?\" He raised his eyes languidly from the old black-letter volume which he had opened. \"It is cocaine,\" he said,-\"a seven-per-cent. solution. Would you care to try it?\" \"No, indeed,\" I answered, brusquely. \"My constitution has not got over the Afghan campaign yet. I\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the main character that the story revolves around?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the main character that the story revolves around?\n",
      "A: Sherlock Holmes (model confidence score: 0.865)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Sherlock Holmes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Sherlock Holmes\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Sherlock Holmes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Sherlock Holmes\n",
      "{'bertscore_f1': 0.5970935821533203,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5840288996696472,\n",
      " 'bertscore_recall': 0.6107561588287354,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the detective in the story?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the detective in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.986)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Sherlock Holmes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Sherlock Holmes\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Sherlock Holmes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Sherlock Holmes\n",
      "{'bertscore_f1': 0.5970935821533203,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5840288996696472,\n",
      " 'bertscore_recall': 0.6107561588287354,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the main protagonist in the story?\n",
      "Expected Answer: Sherlock Holmes\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the main protagonist in the story?\n",
      "A: Sherlock Holmes (model confidence score: 0.964)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Sherlock Holmes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Sherlock Holmes\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Sherlock Holmes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Sherlock Holmes\n",
      "{'bertscore_f1': 0.5970935821533203,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5840288996696472,\n",
      " 'bertscore_recall': 0.6107561588287354,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What did Holmes take from the morocco case?\n",
      "Expected Answer: Syringe\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What did Holmes take from the morocco case?\n",
      "A: hypodermic syringe (model confidence score: 0.688)\n",
      "{'bertscore_f1': 0.7596561908721924,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6908412575721741,\n",
      " 'bertscore_recall': 0.843697190284729,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.938364181772037}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> seringue hypodermique\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> hypodermic syringe\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Syrienne hypodérmique\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Hypodermic Syrian\n",
      "{'bertscore_f1': 0.7814875245094299,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.778852105140686,\n",
      " 'bertscore_recall': 0.7841407656669617,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.642116136129505}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What was noticeable about Holmes' forearm and wrist?\n",
      "Expected Answer: Puncture-marks\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What was noticeable about Holmes' forearm and wrist?\n",
      "A: innumerable puncture-marks (model confidence score: 0.415)\n",
      "{'bertscore_f1': 0.7874923944473267,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.736612856388092,\n",
      " 'bertscore_recall': 0.8459222912788391,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 0.9593498319928196}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> innombrables marques de perforation\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> innumerable perforation marks\n",
      "{'bertscore_f1': 0.8537605404853821,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8769773244857788,\n",
      " 'bertscore_recall': 0.8317412734031677,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.9436902371257793}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Nombreuses marques de points\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> A number of points\n",
      "{'bertscore_f1': 0.6302395462989807,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.668339729309082,\n",
      " 'bertscore_recall': 0.596248984336853,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.562992361134147}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Describe Holmes' manner while preparing the injection.\n",
      "Expected Answer: Nonchalant\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Describe Holmes' manner while preparing the injection.\n",
      "A: With his long, white, nervous fingers he adjusted the delicate needle (model confidence score: 0.183)\n",
      "{'bertscore_f1': 0.40816348791122437,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.40705710649490356,\n",
      " 'bertscore_recall': 0.40927591919898987,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2710701090945207}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Avec ses doigts longs, blancs, nerveux, il a ajusté l'aiguille délicate\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> With his long, white, nervous fingers, he adjusted the delicate needle\n",
      "{'bertscore_f1': 0.978082537651062,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9741328954696655,\n",
      " 'bertscore_recall': 0.9820643067359924,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Avec ses doigts longs, blancs, nerveux, il ajuste la délicate aiguille\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> With his long, white, nervous fingers, he adjusts the delicate needle.\n",
      "{'bertscore_f1': 0.9710554480552673,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9641019105911255,\n",
      " 'bertscore_recall': 0.9781099557876587,\n",
      " 'rouge1': 0.9090909090909091,\n",
      " 'rouge2': 0.8000000000000002,\n",
      " 'rougeL': 0.9090909090909091,\n",
      " 'rougeLsum': 0.9090909090909091,\n",
      " 'spacy_sim': 0.9921104473261028}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What substance did Holmes use that day?\n",
      "Expected Answer: Cocaine\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What substance did Holmes use that day?\n",
      "A: cocaine (model confidence score: 0.461)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> cocaïne\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Cocaine\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> La cocaïne\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The cocaine\n",
      "{'bertscore_f1': 0.6776700615882874,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6879561543464661,\n",
      " 'bertscore_recall': 0.667686939239502,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What emotion does the narrator feel towards Holmes' habit?\n",
      "Expected Answer: Irritation\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What emotion does the narrator feel towards Holmes' habit?\n",
      "A: irritable (model confidence score: 0.755)\n",
      "{'bertscore_f1': 0.8308284878730774,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8308284878730774,\n",
      " 'bertscore_recall': 0.8308284878730774,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.7053101909462468}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> irritable\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> irritable\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> irritable\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Irritable\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What made the narrator more irritable over time?\n",
      "Expected Answer: Holmes' habit\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What made the narrator more irritable over time?\n",
      "A: Sherlock Holmes (model confidence score: 0.322)\n",
      "{'bertscore_f1': 0.5875648856163025,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5778283476829529,\n",
      " 'bertscore_recall': 0.5976350903511047,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.3614692119752116}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Sherlock Holmes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Sherlock Holmes\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Sherlock Holmes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Sherlock Holmes\n",
      "{'bertscore_f1': 0.5970935821533203,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5840288996696472,\n",
      " 'bertscore_recall': 0.6107561588287354,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "Found: ['antagonist.0.md', 'antagonist.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "His name, I have every reason to believe, is Jonathan Small. He is a poorly-educated man, small, active, with his right leg off, and wearing a wooden stump which is worn away upon the inner side. His left boot has a coarse, square-toed sole, with an iron band round the heel. He is a middle-aged man, much sunburned, and has been a convict. These few indications may be of some assistance to you, coupled with the fact that there is a good deal of skin missing from the palm of his hand. The other man-\" \"Ah! the other man-?\" asked Athelney Jones, in a sneering voice, but impressed none the less, as I could easily see, by the precision of the other's manner. \"Is a rather curious person,\" said Sherlock Holmes, turning upon his heel. \"I hope before very long to be able to introduce you to the pair of them.-A word with you, Watson.\" He led me out to the head of the stair. \"This unexpected occurrence,\" he said, \"has caused us rather to lose sight of the original purpose of our journey.\" \"I have just been thinking so,\" I answered. \"It is not right that Miss Morstan should remain in this stricken house.\" \"No. You must escort her home. She lives with Mrs. Cecil Forrester, in Lower Camberwell: so it is not very far. I will wait for you here if you will drive out again. Or perhaps you are too tired?\" \"By no means. I don't think I could rest until I know more of this fantastic business. I have seen something of the rough side of life, but I give you my word that this quick succession of strange surprises to-night has shaken my nerve completely. I should like, however, to see the matter through with\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the primary antagonist or perpetrator in the story?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the primary antagonist or perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.943)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Jonathan Small\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Jonathan Small\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Jonathan petit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Jonathan Little\n",
      "{'bertscore_f1': 0.7546383142471313,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7218294143676758,\n",
      " 'bertscore_recall': 0.7905718088150024,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.5121400034479703}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the perpetrator in the story?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the perpetrator in the story?\n",
      "A: Jonathan Small (model confidence score: 0.979)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Jonathan Small\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Jonathan Small\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Jonathan petit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Jonathan Little\n",
      "{'bertscore_f1': 0.7546383142471313,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7218294143676758,\n",
      " 'bertscore_recall': 0.7905718088150024,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.5121400034479703}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the person responsible for the crime?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the person responsible for the crime?\n",
      "A: Jonathan Small (model confidence score: 0.971)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Jonathan Small\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Jonathan Small\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Jonathan petit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Jonathan Little\n",
      "{'bertscore_f1': 0.7546383142471313,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7218294143676758,\n",
      " 'bertscore_recall': 0.7905718088150024,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.5121400034479703}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What was Jonathan Small's previous legal status?\n",
      "Expected Answer: Convict\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What was Jonathan Small's previous legal status?\n",
      "A: convict (model confidence score: 0.675)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> condamné\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Sentenced\n",
      "{'bertscore_f1': 0.5667901039123535,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5667901039123535,\n",
      " 'bertscore_recall': 0.5667901039123535,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.6165395784663085}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> condamné\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> condemned\n",
      "{'bertscore_f1': 0.5334381461143494,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5747917890548706,\n",
      " 'bertscore_recall': 0.49763554334640503,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.4591384943601961}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Which limb is missing from Jonathan Small's body?\n",
      "Expected Answer: Right leg\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Which limb is missing from Jonathan Small's body?\n",
      "A: right leg (model confidence score: 0.639)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> jambe droite\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg, right leg\n",
      "{'bertscore_f1': 0.24820546805858612,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.17968247830867767,\n",
      " 'bertscore_recall': 0.4012089967727661,\n",
      " 'rouge1': 0.037037037037037035,\n",
      " 'rouge2': 0.01886792452830189,\n",
      " 'rougeL': 0.037037037037037035,\n",
      " 'rougeLsum': 0.037037037037037035,\n",
      " 'spacy_sim': 0.9999999685510376}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> La jambe droite\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Right Foot\n",
      "{'bertscore_f1': 0.7842410206794739,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.759447455406189,\n",
      " 'bertscore_recall': 0.8107081055641174,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.7335466933217062}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What physical disability does Jonathan Small have?\n",
      "Expected Answer: Right leg off\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What physical disability does Jonathan Small have?\n",
      "A: right leg off (model confidence score: 0.34)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> jambe droite éteinte\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> right leg off\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> La jambe droite\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Right Foot\n",
      "{'bertscore_f1': 0.5876633524894714,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6156798601150513,\n",
      " 'bertscore_recall': 0.5620855689048767,\n",
      " 'rouge1': 0.3333333333333333,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.3333333333333333,\n",
      " 'rougeLsum': 0.3333333333333333,\n",
      " 'spacy_sim': 0.7335466933217062}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What is the condition of Jonathan Small's wooden stump?\n",
      "Expected Answer: Worn away\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What is the condition of Jonathan Small's wooden stump?\n",
      "A: worn away upon the inner side (model confidence score: 0.907)\n",
      "{'bertscore_f1': 0.7328334450721741,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6570538878440857,\n",
      " 'bertscore_recall': 0.8283714652061462,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.33333333333333337,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9144565901296556}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> usés sur le côté intérieur\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> worn on the inside side\n",
      "{'bertscore_f1': 0.824790358543396,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8241846561431885,\n",
      " 'bertscore_recall': 0.8253970146179199,\n",
      " 'rouge1': 0.5454545454545454,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5454545454545454,\n",
      " 'rougeLsum': 0.5454545454545454,\n",
      " 'spacy_sim': 0.7920655843604467}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Porter sur le côté intérieur\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Getting on the inner side\n",
      "{'bertscore_f1': 0.6628819704055786,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6591798067092896,\n",
      " 'bertscore_recall': 0.6666259765625,\n",
      " 'rouge1': 0.5454545454545454,\n",
      " 'rouge2': 0.4444444444444445,\n",
      " 'rougeL': 0.5454545454545454,\n",
      " 'rougeLsum': 0.5454545454545454,\n",
      " 'spacy_sim': 0.6240849400733904}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What is the condition of Small's hand?\n",
      "Expected Answer: Missing skin\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What is the condition of Small's hand?\n",
      "A: there is a good deal of skin missing from the palm of his hand (model confidence score: 0.291)\n",
      "{'bertscore_f1': 0.5884615182876587,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5076013803482056,\n",
      " 'bertscore_recall': 0.6999648809432983,\n",
      " 'rouge1': 0.25,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.125,\n",
      " 'rougeLsum': 0.125,\n",
      " 'spacy_sim': 0.7664694971682984}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Il manque beaucoup de peau dans la paume de sa main.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> He lacks much skin in the palm of his hand.\n",
      "{'bertscore_f1': 0.8545059561729431,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.884735107421875,\n",
      " 'bertscore_recall': 0.8262742757797241,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.3636363636363637,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8875429587100728}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Il y a beaucoup de peau manquant de la palme de sa main\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> There is a lot of skin lacking from the palm of his hand.\n",
      "{'bertscore_f1': 0.9274672269821167,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9291377067565918,\n",
      " 'bertscore_recall': 0.9258027076721191,\n",
      " 'rouge1': 0.8148148148148148,\n",
      " 'rouge2': 0.64,\n",
      " 'rougeL': 0.8148148148148148,\n",
      " 'rougeLsum': 0.8148148148148148,\n",
      " 'spacy_sim': 0.8982963307786391}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What is missing from Jonathan Small's hand?\n",
      "Expected Answer: Skin on palm\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What is missing from Jonathan Small's hand?\n",
      "A: skin (model confidence score: 0.786)\n",
      "{'bertscore_f1': 0.6255573034286499,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6703099608421326,\n",
      " 'bertscore_recall': 0.5864064693450928,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8865567736112707}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> peau\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin, skin.\n",
      "{'bertscore_f1': 0.20015910267829895,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.13518615067005157,\n",
      " 'bertscore_recall': 0.3853795528411865,\n",
      " 'rouge1': 0.015873015873015872,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.015873015873015872,\n",
      " 'rougeLsum': 0.015873015873015872,\n",
      " 'spacy_sim': 0.9999999686303157}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> La peau\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The skin\n",
      "{'bertscore_f1': 0.6505929827690125,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6209838390350342,\n",
      " 'bertscore_recall': 0.6831671595573425,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 1.0}\n",
      "Found: ['crime.0.md', 'crime.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "\"We earned a living at this time by my exhibiting poor Tonga at fairs and other such places as the black cannibal. He would eat raw meat and dance his war-dance: so we always had a hatful of pennies after a day's work. I still heard all the news from Pondicherry Lodge, and for some years there was no news to hear, except that they were hunting for the treasure. At last, however, came what we had waited for so long. The treasure had been found. It was up at the top of the house, in Mr. Bartholomew Sholto's chemical laboratory. I came at once and had a look at the place, but I could not see how with my wooden leg I was to make my way up to it. I learned, however, about a trap-door in the roof, and also about Mr. Sholto's supper-hour. It seemed to me that I could manage the thing easily through Tonga. I brought him out with me with a long rope wound round his waist. He could climb like a cat, and he soon made his way through the roof, but, as ill luck would have it, Bartholomew Sholto was still in the room, to his cost. Tonga thought he had done something very clever in killing him, for when I came up by the rope I found him strutting about as proud as a peacock. Very much surprised was he when I made at him with the rope's end and cursed him for a little blood-thirsty imp. I took the treasure-box and let it down, and then slid down myself, having first left the sign of the four upon the table, to show that the jewels had come back at last to those who had most right to them. Tonga then\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What criminal activity took place?\n",
      "Expected Answer: Theft of a treasure\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What criminal activity took place?\n",
      "A: black cannibal (model confidence score: 0.003)\n",
      "{'bertscore_f1': 0.4273728132247925,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.39258134365081787,\n",
      " 'bertscore_recall': 0.46893051266670227,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.23828533004285166}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Cannibales noirs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Black cannibals\n",
      "{'bertscore_f1': 0.6860430836677551,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.642586350440979,\n",
      " 'bertscore_recall': 0.7358038425445557,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9870996558250138}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le cannibale noir\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Black Cannibal\n",
      "{'bertscore_f1': 0.8135150074958801,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7734206318855286,\n",
      " 'bertscore_recall': 0.8579937815666199,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Where was the treasure found?\n",
      "Expected Answer: Chemical laboratory\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Where was the treasure found?\n",
      "A: in Mr. Bartholomew Sholto's chemical laboratory (model confidence score: 0.235)\n",
      "{'bertscore_f1': 0.572414219379425,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4461829960346222,\n",
      " 'bertscore_recall': 0.7982498407363892,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.2857142857142857,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.9073447992236038}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> dans le laboratoire chimique de M. Bartholomew Sholto\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> in the chemical laboratory of Mr Bartholomew Sholto\n",
      "{'bertscore_f1': 0.9155999422073364,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9155999422073364,\n",
      " 'bertscore_recall': 0.9155999422073364,\n",
      " 'rouge1': 0.7999999999999999,\n",
      " 'rouge2': 0.4615384615384615,\n",
      " 'rougeL': 0.5333333333333333,\n",
      " 'rougeLsum': 0.5333333333333333,\n",
      " 'spacy_sim': 1.0000000327215188}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> dans le laboratoire chimique de M. Bartholomew Sholto\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Chemical Laboratory of Mr. Bartholomew Sholto\n",
      "{'bertscore_f1': 0.901730477809906,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.901730477809906,\n",
      " 'bertscore_recall': 0.9017304182052612,\n",
      " 'rouge1': 0.7142857142857143,\n",
      " 'rouge2': 0.5,\n",
      " 'rougeL': 0.42857142857142855,\n",
      " 'rougeLsum': 0.42857142857142855,\n",
      " 'spacy_sim': 1.0000000327215188}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Where did the crime take place\n",
      "Expected Answer: Chemical laboratory\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Where did the crime take place\n",
      "A: Pondicherry Lodge (model confidence score: 0.025)\n",
      "{'bertscore_f1': 0.5715089440345764,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5792762041091919,\n",
      " 'bertscore_recall': 0.5639472603797913,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0041812132145634985}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Loge Pondichéry\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Loge Pondicherry\n",
      "{'bertscore_f1': 0.7275165915489197,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7258933782577515,\n",
      " 'bertscore_recall': 0.7291470766067505,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.2439168801481622}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le Lodge de Pondicherry\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Lodge of Pondicherry\n",
      "{'bertscore_f1': 0.8195112347602844,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7945088148117065,\n",
      " 'bertscore_recall': 0.8461385369300842,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.3333333333333333,\n",
      " 'rougeLsum': 0.3333333333333333,\n",
      " 'spacy_sim': 0.9999999852765572}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: How did Tonga access the roof?\n",
      "Expected Answer: Trap-door\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: How did Tonga access the roof?\n",
      "A: a long rope wound round his waist (model confidence score: 0.591)\n",
      "{'bertscore_f1': 0.5500807762145996,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4896923005580902,\n",
      " 'bertscore_recall': 0.627458393573761,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.38928000231795745}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> une longue corde de blessure autour de sa taille\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> a long wound rope around its waist\n",
      "{'bertscore_f1': 0.8825280070304871,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8825279474258423,\n",
      " 'bertscore_recall': 0.8825280070304871,\n",
      " 'rouge1': 0.7142857142857143,\n",
      " 'rouge2': 0.16666666666666666,\n",
      " 'rougeL': 0.5714285714285714,\n",
      " 'rougeLsum': 0.5714285714285714,\n",
      " 'spacy_sim': 0.95086338734645}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Une longue blessure autour de son ventre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> A long wound around his stomach.\n",
      "{'bertscore_f1': 0.8111356496810913,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.829974889755249,\n",
      " 'bertscore_recall': 0.7931326031684875,\n",
      " 'rouge1': 0.6153846153846153,\n",
      " 'rouge2': 0.1818181818181818,\n",
      " 'rougeL': 0.6153846153846153,\n",
      " 'rougeLsum': 0.6153846153846153,\n",
      " 'spacy_sim': 0.8105174987030593}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What hindered Jonathan's access to the treasure?\n",
      "Expected Answer: Wooden leg\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What hindered Jonathan's access to the treasure?\n",
      "A: Bartholomew Sholto (model confidence score: 0.236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Documents/GitHub/UTK-Classes/CS524-Natural-Language-Processing/projects/ChatPI/scratchbooks/src/utils.py:90: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  score = doc1.similarity(doc2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bertscore_f1': 0.505920946598053,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4350338578224182,\n",
      " 'bertscore_recall': 0.6044065952301025,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Bartholomew Sholto\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Bartholomew Sholto\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le Bartholomew Sholto\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Bartholomew Sholto\n",
      "{'bertscore_f1': 0.9058734774589539,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8884923458099365,\n",
      " 'bertscore_recall': 0.9239482283592224,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who climbed through the roof for Jonathan Small?\n",
      "Expected Answer: Tonga\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who climbed through the roof for Jonathan Small?\n",
      "A: Tonga (model confidence score: 0.018)\n",
      "{'bertscore_f1': 0.9999999403953552,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9999999403953552,\n",
      " 'bertscore_recall': 0.9999999403953552,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> États-Unis d'Amérique\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> United States of America\n",
      "{'bertscore_f1': 0.4590018689632416,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4737217426300049,\n",
      " 'bertscore_recall': 0.44516921043395996,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.09195951605392053}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Tonga\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Tonga\n",
      "{'bertscore_f1': 0.9999999403953552,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9999999403953552,\n",
      " 'bertscore_recall': 0.9999999403953552,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who was still in the room when Tonga entered?\n",
      "Expected Answer: Bartholomew Sholto\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who was still in the room when Tonga entered?\n",
      "A: Bartholomew Sholto (model confidence score: 0.912)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Bartholomew Sholto\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Bartholomew Sholto\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le Bartholomew Sholto\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Bartholomew Sholto\n",
      "{'bertscore_f1': 0.9058734774589539,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8884923458099365,\n",
      " 'bertscore_recall': 0.9239482283592224,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What did Tonga do to Bartholomew Sholto?\n",
      "Expected Answer: Killed him\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What did Tonga do to Bartholomew Sholto?\n",
      "A: killing him (model confidence score: 0.087)\n",
      "{'bertscore_f1': 0.8936544060707092,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8936544060707092,\n",
      " 'bertscore_recall': 0.8936544060707092,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7830225260720117}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> l'assassiner\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Kill him.\n",
      "{'bertscore_f1': 0.8488739132881165,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.822228729724884,\n",
      " 'bertscore_recall': 0.877303957939148,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.6437444708600987}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le tuer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Kill him\n",
      "{'bertscore_f1': 0.8991564512252808,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8991564512252808,\n",
      " 'bertscore_recall': 0.8991564512252808,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.6437444708600987}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What symbol did the narrator leave on the table?\n",
      "Expected Answer: Sign of the four\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What symbol did the narrator leave on the table?\n",
      "A: the sign of the four (model confidence score: 0.684)\n",
      "{'bertscore_f1': 0.7846453785896301,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.784517228603363,\n",
      " 'bertscore_recall': 0.7847735285758972,\n",
      " 'rouge1': 0.888888888888889,\n",
      " 'rouge2': 0.8571428571428571,\n",
      " 'rougeL': 0.888888888888889,\n",
      " 'rougeLsum': 0.888888888888889,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> le signe des quatre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> the sign of the four\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le signe des quatre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Sign of the Four\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "Found: ['evidence.0.md', 'evidence.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "\"Just sit in the corner there, that your footprints may not complicate matters. Now to work! In the first place, how did these folk come, and how did they go? The door has not been opened since last night. How of the window?\" He carried the lamp across to it, muttering his observations aloud the while, but addressing them to himself rather than to me. \"Window is snibbed on the inner side. Framework is solid. No hinges at the side. Let us open it. No water-pipe near. Roof quite out of reach. Yet a man has mounted by the window. It rained a little last night. Here is the print of a foot in mould upon the sill. And here is a circular muddy mark, and here again upon the floor, and here again by the table. See here, Watson! This is really a very pretty demonstration.\" I looked at the round, well-defined muddy discs. \"This is not a footmark,\" said I. \"It is something much more valuable to us. It is the impression of a wooden stump. You see here on the sill is the boot-mark, a heavy boot with the broad metal heel, and beside it is the mark of the timber-toe.\" \"It is the wooden-legged man.\" \"Quite so. But there has been some one else,-a very able and efficient ally. Could you scale that wall, doctor?\" I looked out of the open window. The moon still shone brightly on that angle of the house. We were a good sixty feet from the ground, and, look where I would, I could see no foothold, nor as much as a crevice in the brick-work. \"It is absolutely impossible,\" I answered. \"Without aid it is so. But suppose you had a friend up here who lowered you this good stout\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What kind of mark was found beside the boot-mark?\n",
      "Expected Answer: Circular muddy mark\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What kind of mark was found beside the boot-mark?\n",
      "A: timber-toe (model confidence score: 0.782)\n",
      "{'bertscore_f1': 0.6372380256652832,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6372380256652832,\n",
      " 'bertscore_recall': 0.6372380256652832,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.413825731983079}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> orteil de bois\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Wood toe\n",
      "{'bertscore_f1': 0.7042015790939331,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.707008957862854,\n",
      " 'bertscore_recall': 0.7014163732528687,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.9003705347008911}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le bois-toe\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The wood-toe\n",
      "{'bertscore_f1': 0.8405290246009827,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8405289649963379,\n",
      " 'bertscore_recall': 0.8405289649963379,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.9003705347008911}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who was suspected due to the mark?\n",
      "Expected Answer: Wooden-legged man\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who was suspected due to the mark?\n",
      "A: the wooden-legged man (model confidence score: 0.425)\n",
      "{'bertscore_f1': 0.8060775399208069,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8125274777412415,\n",
      " 'bertscore_recall': 0.7997292280197144,\n",
      " 'rouge1': 0.8571428571428571,\n",
      " 'rouge2': 0.8,\n",
      " 'rougeL': 0.8571428571428571,\n",
      " 'rougeLsum': 0.8571428571428571,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> l'homme à pattes de bois\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> the man with wooden legs\n",
      "{'bertscore_f1': 0.827915370464325,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.814047634601593,\n",
      " 'bertscore_recall': 0.8422638177871704,\n",
      " 'rouge1': 0.6666666666666665,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.9107494354327645}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> L’homme à pied de bois\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Man Walking in Wood\n",
      "{'bertscore_f1': 0.7223724126815796,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7244052290916443,\n",
      " 'bertscore_recall': 0.720350980758667,\n",
      " 'rouge1': 0.4444444444444445,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4444444444444445,\n",
      " 'rougeLsum': 0.4444444444444445,\n",
      " 'spacy_sim': 0.8234023118082006}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What evidence suggests that the perpetrator committed the crime?\n",
      "Expected Answer: the mark of the timber-toe\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What evidence suggests that the perpetrator committed the crime?\n",
      "A: a man has mounted by the window (model confidence score: 0.066)\n",
      "{'bertscore_f1': 0.5871443748474121,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5897021293640137,\n",
      " 'bertscore_recall': 0.5846086144447327,\n",
      " 'rouge1': 0.15384615384615383,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.15384615384615383,\n",
      " 'rougeLsum': 0.15384615384615383,\n",
      " 'spacy_sim': 0.3902030399185256}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> un homme est monté par la fenêtre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> a man came up out the window\n",
      "{'bertscore_f1': 0.8155409693717957,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8268754482269287,\n",
      " 'bertscore_recall': 0.8045130968093872,\n",
      " 'rouge1': 0.5714285714285714,\n",
      " 'rouge2': 0.3333333333333333,\n",
      " 'rougeL': 0.5714285714285714,\n",
      " 'rougeLsum': 0.5714285714285714,\n",
      " 'spacy_sim': 0.8166387585846083}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Un homme est monté par la fenêtre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> A man climbed through the window\n",
      "{'bertscore_f1': 0.8190160393714905,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8476966619491577,\n",
      " 'bertscore_recall': 0.7922126054763794,\n",
      " 'rouge1': 0.6153846153846153,\n",
      " 'rouge2': 0.3636363636363636,\n",
      " 'rougeL': 0.6153846153846153,\n",
      " 'rougeLsum': 0.6153846153846153,\n",
      " 'spacy_sim': 0.9035370055543007}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is suspected to have mounted by the window?\n",
      "Expected Answer: Wooden-legged man\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is suspected to have mounted by the window?\n",
      "A: wooden-legged man (model confidence score: 0.177)\n",
      "{'bertscore_f1': 0.9999999403953552,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9999999403953552,\n",
      " 'bertscore_recall': 0.9999999403953552,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Homme à pattes de bois\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Man with wooden legs\n",
      "{'bertscore_f1': 0.6962772011756897,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6959792971611023,\n",
      " 'bertscore_recall': 0.696575403213501,\n",
      " 'rouge1': 0.5714285714285715,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.28571428571428575,\n",
      " 'rougeLsum': 0.28571428571428575,\n",
      " 'spacy_sim': 0.9107494354327645}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> L’homme à pied de bois\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Man Walking in Wood\n",
      "{'bertscore_f1': 0.6651334166526794,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.667697548866272,\n",
      " 'bertscore_recall': 0.6625888347625732,\n",
      " 'rouge1': 0.25,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.25,\n",
      " 'rougeLsum': 0.25,\n",
      " 'spacy_sim': 0.8234023118082006}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What specific feature of the boot was noticed?\n",
      "Expected Answer: Metal heel\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What specific feature of the boot was noticed?\n",
      "A: broad metal heel (model confidence score: 0.81)\n",
      "{'bertscore_f1': 0.8221580982208252,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8001294136047363,\n",
      " 'bertscore_recall': 0.8454340696334839,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 0.8811241967815432}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Talon en métal large\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Large metal heel\n",
      "{'bertscore_f1': 0.9440615177154541,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9440615177154541,\n",
      " 'bertscore_recall': 0.9440615177154541,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.5,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.8846123360361831}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Extrait métallique\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Metal Extract\n",
      "{'bertscore_f1': 0.528948962688446,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4854705333709717,\n",
      " 'bertscore_recall': 0.5809813737869263,\n",
      " 'rouge1': 0.3333333333333333,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.3333333333333333,\n",
      " 'rougeLsum': 0.3333333333333333,\n",
      " 'spacy_sim': 0.7104403262810823}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What specific feature of the boot is mentioned?\n",
      "Expected Answer: Broad metal heel\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What specific feature of the boot is mentioned?\n",
      "A: broad metal heel (model confidence score: 0.765)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Talon en métal large\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Large metal heel\n",
      "{'bertscore_f1': 0.9440615177154541,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9440615177154541,\n",
      " 'bertscore_recall': 0.9440615177154541,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.5,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 0.8846123360361831}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Extrait métallique\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Metal Extract\n",
      "{'bertscore_f1': 0.528948962688446,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.4854705333709717,\n",
      " 'bertscore_recall': 0.5809813737869263,\n",
      " 'rouge1': 0.3333333333333333,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.3333333333333333,\n",
      " 'rougeLsum': 0.3333333333333333,\n",
      " 'spacy_sim': 0.7104403262810823}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: How did the characters conclude that someone entered through the window?\n",
      "Expected Answer: Footprint on sill\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: How did the characters conclude that someone entered through the window?\n",
      "A: a man has mounted by the window (model confidence score: 0.166)\n",
      "{'bertscore_f1': 0.4940081536769867,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.49675849080085754,\n",
      " 'bertscore_recall': 0.49128806591033936,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.42442357558288807}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> un homme est monté par la fenêtre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> a man came up out the window\n",
      "{'bertscore_f1': 0.8155409693717957,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8268754482269287,\n",
      " 'bertscore_recall': 0.8045130968093872,\n",
      " 'rouge1': 0.5714285714285714,\n",
      " 'rouge2': 0.3333333333333333,\n",
      " 'rougeL': 0.5714285714285714,\n",
      " 'rougeLsum': 0.5714285714285714,\n",
      " 'spacy_sim': 0.8166387585846083}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Un homme est monté par la fenêtre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> A man climbed through the window\n",
      "{'bertscore_f1': 0.8190160393714905,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8476966619491577,\n",
      " 'bertscore_recall': 0.7922126054763794,\n",
      " 'rouge1': 0.6153846153846153,\n",
      " 'rouge2': 0.3636363636363636,\n",
      " 'rougeL': 0.6153846153846153,\n",
      " 'rougeLsum': 0.6153846153846153,\n",
      " 'spacy_sim': 0.9035370055543007}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What did they observe on the window sill?\n",
      "Expected Answer: Footprint\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What did they observe on the window sill?\n",
      "A: print of a foot in mould (model confidence score: 0.052)\n",
      "{'bertscore_f1': 0.6143780946731567,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5869958400726318,\n",
      " 'bertscore_recall': 0.6444400548934937,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.5564579195422855}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> impression d'un pied dans un moule\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> impression of a foot in a mould\n",
      "{'bertscore_f1': 0.8723732233047485,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8438315391540527,\n",
      " 'bertscore_recall': 0.9029133319854736,\n",
      " 'rouge1': 0.7692307692307692,\n",
      " 'rouge2': 0.5454545454545454,\n",
      " 'rougeL': 0.7692307692307692,\n",
      " 'rougeLsum': 0.7692307692307692,\n",
      " 'spacy_sim': 0.8714820896357562}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> L’impression d’un pied en mould\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The impression of a mould foot\n",
      "{'bertscore_f1': 0.7448508739471436,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7286816835403442,\n",
      " 'bertscore_recall': 0.7617539167404175,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.20000000000000004,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.8714820884552592}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: How far from the ground was the open window?\n",
      "Expected Answer: Sixty feet\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: How far from the ground was the open window?\n",
      "A: sixty feet (model confidence score: 0.39)\n",
      "{'bertscore_f1': 1.000000238418579,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.000000238418579,\n",
      " 'bertscore_recall': 1.000000238418579,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> 60 pieds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> 60 feet\n",
      "{'bertscore_f1': 0.8570001721382141,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8875724077224731,\n",
      " 'bertscore_recall': 0.8284639120101929,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.5446211791289186}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> 60 pieds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> 60 feet\n",
      "{'bertscore_f1': 0.8570001721382141,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8875724077224731,\n",
      " 'bertscore_recall': 0.8284639120101929,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.5446211791289186}\n",
      "Found: ['resolution.0.md', 'resolution.qa.md']\n",
      "################################################################################\n",
      "################################################################################\n",
      "A map is drawn for them by an Englishman named Jonathan Small. You remember that we saw the name upon the chart in Captain Morstan's possession. He had signed it in behalf of himself and his associates,-the sign of the four, as he somewhat dramatically called it. Aided by this chart, the officers-or one of them-gets the treasure and brings it to England, leaving, we will suppose, some condition under which he received it unfulfilled. Now, then, why did not Jonathan Small get the treasure himself? The answer is obvious. The chart is dated at a time when Morstan was brought into close association with convicts. Jonathan Small did not get the treasure because he and his associates were themselves convicts and could not get away.\" \"But that is mere speculation,\" said I. \"It is more than that. It is the only hypothesis which covers the facts. Let us see how it fits in with the sequel. Major Sholto remains at peace for some years, happy in the possession of his treasure. Then he receives a letter from India which gives him a great fright. What was that?\" \"A letter to say that the men whom he had wronged had been set free.\" \"Or had escaped. That is much more likely, for he would have known what their term of imprisonment was. It would not have been a surprise to him. What does he do then? He guards himself against a wooden-legged man,-a white man, mark you, for he mistakes a white tradesman for him, and actually fires a pistol at him. Now, only one white man's name is on the chart. The others are Hindoos or Mohammedans. There is no other white man. Therefore we may say with confidence that the wooden-legged man is identical with Jonathan Small. Does\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who drew the map for the treasure?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who drew the map for the treasure?\n",
      "A: Jonathan Small (model confidence score: 0.778)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Jonathan Small\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Jonathan Small\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Jonathan petit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Jonathan Little\n",
      "{'bertscore_f1': 0.7546383142471313,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7218294143676758,\n",
      " 'bertscore_recall': 0.7905718088150024,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.5121400034479703}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Whose possession was the chart originally in?\n",
      "Expected Answer: Captain Morstan\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Whose possession was the chart originally in?\n",
      "A: Captain Morstan's (model confidence score: 0.758)\n",
      "{'bertscore_f1': 0.824133574962616,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.780864953994751,\n",
      " 'bertscore_recall': 0.8724786043167114,\n",
      " 'rouge1': 0.8,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.8,\n",
      " 'rougeLsum': 0.8,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Le capitaine Morstan's\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Captain Morstan's\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le Capitaine Morstan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Captain Morstan\n",
      "{'bertscore_f1': 0.7255354523658752,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7296009659767151,\n",
      " 'bertscore_recall': 0.7215150594711304,\n",
      " 'rouge1': 0.6666666666666666,\n",
      " 'rouge2': 0.5,\n",
      " 'rougeL': 0.6666666666666666,\n",
      " 'rougeLsum': 0.6666666666666666,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What is the name of the group associated with Small?\n",
      "Expected Answer: The sign of the four\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What is the name of the group associated with Small?\n",
      "A: he and his associates (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.5136165618896484,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5636311769485474,\n",
      " 'bertscore_recall': 0.47175469994544983,\n",
      " 'rouge1': 0.0,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.0,\n",
      " 'rougeLsum': 0.0,\n",
      " 'spacy_sim': 0.2424952491604731}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> lui et ses associés\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> he and his associates\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Il et ses associés\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> He and his associates\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What symbol did Jonathan Small use on the chart?\n",
      "Expected Answer: Sign of the four\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What symbol did Jonathan Small use on the chart?\n",
      "A: the sign of the four (model confidence score: 0.0)\n",
      "{'bertscore_f1': 0.7846453785896301,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.784517228603363,\n",
      " 'bertscore_recall': 0.7847735285758972,\n",
      " 'rouge1': 0.888888888888889,\n",
      " 'rouge2': 0.8571428571428571,\n",
      " 'rougeL': 0.888888888888889,\n",
      " 'rougeLsum': 0.888888888888889,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> le signe des quatre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> the sign of the four\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Le signe des quatre\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The Sign of the Four\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "Expected Answer: He was a convict\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Why couldn't Jonathan Small retrieve the treasure himself?\n",
      "A: he and his associates were themselves convicts and could not get away (model confidence score: 0.347)\n",
      "{'bertscore_f1': 0.6252064108848572,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5234562158584595,\n",
      " 'bertscore_recall': 0.7760577201843262,\n",
      " 'rouge1': 0.125,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.125,\n",
      " 'rougeLsum': 0.125,\n",
      " 'spacy_sim': 0.5283875959223574}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> lui et ses associés étaient eux-mêmes condamnés et ne pouvaient s'échapper\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> he and his associates were themselves condemned and could not escape\n",
      "{'bertscore_f1': 0.8974037170410156,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9106810092926025,\n",
      " 'bertscore_recall': 0.8845080733299255,\n",
      " 'rouge1': 0.7826086956521738,\n",
      " 'rouge2': 0.6666666666666666,\n",
      " 'rougeL': 0.7826086956521738,\n",
      " 'rougeLsum': 0.7826086956521738,\n",
      " 'spacy_sim': 0.6371956295563859}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Il et ses collègues étaient eux-mêmes condamnés et ne pouvaient pas partir.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> He and his colleagues were condemned themselves and could not leave.\n",
      "{'bertscore_f1': 0.8345693945884705,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.8454668521881104,\n",
      " 'bertscore_recall': 0.8239493370056152,\n",
      " 'rouge1': 0.6956521739130435,\n",
      " 'rouge2': 0.380952380952381,\n",
      " 'rougeL': 0.6956521739130435,\n",
      " 'rougeLsum': 0.6956521739130435,\n",
      " 'spacy_sim': 0.5409603601314894}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What caused Major Sholto distress?\n",
      "Expected Answer: A letter from India\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What caused Major Sholto distress?\n",
      "A: a letter from India (model confidence score: 0.309)\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> une lettre de l'Inde\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> a letter from India\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Une lettre de l'Inde\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> A letter from India\n",
      "{'bertscore_f1': 1.0000001192092896,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0000001192092896,\n",
      " 'bertscore_recall': 1.0000001192092896,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What did the letter inform Major Sholto?\n",
      "Expected Answer: Men were freed/escaped\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What did the letter inform Major Sholto?\n",
      "A: that the men whom he had wronged had been set free (model confidence score: 0.327)\n",
      "{'bertscore_f1': 0.6127269268035889,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.5836127400398254,\n",
      " 'bertscore_recall': 0.644898533821106,\n",
      " 'rouge1': 0.13333333333333333,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.13333333333333333,\n",
      " 'rougeLsum': 0.13333333333333333,\n",
      " 'spacy_sim': 0.7202586107978194}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> que les hommes qu'il avait injustes avaient été libérés\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> that the men whom he had wronged had been freed\n",
      "{'bertscore_f1': 0.972506046295166,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.9812058210372925,\n",
      " 'bertscore_recall': 0.9639591574668884,\n",
      " 'rouge1': 0.8571428571428572,\n",
      " 'rouge2': 0.8421052631578948,\n",
      " 'rougeL': 0.8571428571428572,\n",
      " 'rougeLsum': 0.8571428571428572,\n",
      " 'spacy_sim': 0.764853442288404}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> que les hommes qu'il avait trompés avaient été libérés\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> The people he had mistaken had been released.\n",
      "{'bertscore_f1': 0.7618502378463745,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7824472188949585,\n",
      " 'bertscore_recall': 0.7423098087310791,\n",
      " 'rouge1': 0.5263157894736842,\n",
      " 'rouge2': 0.23529411764705882,\n",
      " 'rougeL': 0.5263157894736842,\n",
      " 'rougeLsum': 0.5263157894736842,\n",
      " 'spacy_sim': 0.5474898396989032}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: What action did Major Sholto take against the mistaken man?\n",
      "Expected Answer: Fired a pistol\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: What action did Major Sholto take against the mistaken man?\n",
      "A: fires a pistol at him (model confidence score: 0.48)\n",
      "{'bertscore_f1': 0.762391984462738,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.6728178262710571,\n",
      " 'bertscore_recall': 0.8794797658920288,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.3333333333333333,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7630856691898642}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Il tire un pistolet sur lui.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> He's shooting a gun at him.\n",
      "{'bertscore_f1': 0.7999873161315918,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7621152400970459,\n",
      " 'bertscore_recall': 0.841820240020752,\n",
      " 'rouge1': 0.5,\n",
      " 'rouge2': 0.2,\n",
      " 'rougeL': 0.5,\n",
      " 'rougeLsum': 0.5,\n",
      " 'spacy_sim': 0.7062203082588715}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Il a tiré un pistolet sur lui\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> He shot a gun on him.\n",
      "{'bertscore_f1': 0.8057840466499329,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7799753546714783,\n",
      " 'bertscore_recall': 0.8333591222763062,\n",
      " 'rouge1': 0.3636363636363636,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.3636363636363636,\n",
      " 'rougeLsum': 0.3636363636363636,\n",
      " 'spacy_sim': 0.6466305501983983}\n",
      "================================================================================\n",
      "================================================================================\n",
      "Current Question: Who is the only white man on the chart?\n",
      "Expected Answer: Jonathan Small\n",
      "--------------------------------------------------------------------------------\n",
      "model: deepset/roberta-large-squad2\n",
      "Q: Who is the only white man on the chart?\n",
      "A: Jonathan Small (model confidence score: 0.019)\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-en-fr\n",
      "> Jonathan Small\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: Helsinki-NLP/opus-mt-fr-en\n",
      "> Jonathan Small\n",
      "{'bertscore_f1': 1.0,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 1.0,\n",
      " 'bertscore_recall': 1.0,\n",
      " 'rouge1': 1.0,\n",
      " 'rouge2': 1.0,\n",
      " 'rougeL': 1.0,\n",
      " 'rougeLsum': 1.0,\n",
      " 'spacy_sim': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> Jonathan petit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: facebook/m2m100_418M\n",
      "> by Jonathan Little\n",
      "{'bertscore_f1': 0.7546383142471313,\n",
      " 'bertscore_hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.35.0)',\n",
      " 'bertscore_precision': 0.7218294143676758,\n",
      " 'bertscore_recall': 0.7905718088150024,\n",
      " 'rouge1': 0.4,\n",
      " 'rouge2': 0.0,\n",
      " 'rougeL': 0.4,\n",
      " 'rougeLsum': 0.4,\n",
      " 'spacy_sim': 0.5121400034479703}\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"res_tr.csv\"\n",
    "\n",
    "csv_header = [\n",
    "    \"ctx_name\",\n",
    "    \"ctx_fname\",\n",
    "    \"q_idx\",\n",
    "    \"q_text\",\n",
    "    \"q_answer_true\",\n",
    "    \"qa_model\",  # the model that was used to answer the question\n",
    "    \"qa_answer_pred\",  # the answer predicted by the qa model\n",
    "    \"tr_model_name_en_to_fr\",  # the model that was used to translate the answer from english to french\n",
    "    \"tr_model_name_fr_to_en\",  # the model that was used to translate the answer from french to english\n",
    "    \"tr_answer_pred_en_to_fr\",  # the french translation of the original english answer\n",
    "    \"tr_answer_pred_fr_to_en\",  # the english translation of the original french answer\n",
    "]\n",
    "csv_rows = []\n",
    "\n",
    "for ctx_name in [\"protagonist\", \"antagonist\", \"crime\", \"evidence\", \"resolution\"]:\n",
    "    for ctx_idx, (ctx_fname, ctx_text) in enumerate(utils.read_context(ctx_name)):\n",
    "        ctx_fname = os.path.basename(ctx_fname)\n",
    "        print(\"#\" * 80)\n",
    "        print(\"#\" * 80)\n",
    "        print(ctx_text)\n",
    "\n",
    "        for q_idx, (q_text, q_answer_true) in enumerate(utils.read_qa(ctx_name)):\n",
    "            print(\"=\" * 80)\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"Current Question: {q_text}\")\n",
    "            print(f\"Expected Answer: {q_answer_true}\")\n",
    "\n",
    "            q_answers_pred, _ = run_qa_models(\n",
    "                q_text,\n",
    "                ctx_text,\n",
    "                models_qa,\n",
    "                q_answer_true,\n",
    "            )\n",
    "\n",
    "            for qa_model, qa_answer_pred in zip(models_qa, q_answers_pred):\n",
    "                tr_preds, tr_scores = run_tr_models(\n",
    "                    qa_answer_pred,\n",
    "                    models_tr,\n",
    "                )\n",
    "\n",
    "                for tr_m, tr_a, tr_s in zip(models_tr, tr_preds, tr_scores):\n",
    "                    row = [\n",
    "                        ctx_name,\n",
    "                        ctx_fname,\n",
    "                        q_idx,\n",
    "                        q_text,\n",
    "                        q_answer_true,\n",
    "                        qa_model,\n",
    "                        qa_answer_pred,\n",
    "                        tr_m[0],\n",
    "                        tr_m[1],\n",
    "                        tr_a[0],\n",
    "                        tr_a[1],\n",
    "                    ]\n",
    "\n",
    "                    for metric, score in tr_s.items():\n",
    "                        if metric not in csv_header:\n",
    "                            csv_header.append(metric)\n",
    "                        row.append(score)\n",
    "\n",
    "                    csv_rows.append(row)\n",
    "\n",
    "\n",
    "with open(csv_file, \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(csv_header)\n",
    "    writer.writerows(csv_rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
